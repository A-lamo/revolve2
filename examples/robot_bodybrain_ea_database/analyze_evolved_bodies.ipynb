{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Merging Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # path = \"C:\\\\Users\\\\niels\\\\Downloads\\\\CPPN_runs\\\\CSV\"\n",
    "# # path = \"C:\\\\Users\\\\niels\\\\Downloads\\\\GRN_runs\\\\CSV\"\n",
    "# # path = \"C:\\\\Users\\\\niels\\\\Downloads\\\\GRN_system_runs\\\\Random\"\n",
    "# # path = \"C:\\\\Users\\\\niels\\\\Downloads\\\\GRN_system_adv_runs\\\\Random\"\n",
    "# path = \"C:\\\\Users\\\\niels\\\\Downloads\\\\GRN_system_runs\\\\evolution\\\\CSV\"\n",
    "# path = \"C:\\\\Users\\\\niels\\\\Downloads\\\\CPPN\\\\Evolution\"\n",
    "# # Create empty dataframe\n",
    "# df = pd.DataFrame([])\n",
    "\n",
    "# # Get folders\n",
    "# folders = os.listdir(path)\n",
    "# folders = [folder for folder in folders if os.path.isdir(os.path.join(path, folder))]\n",
    "# assert len(folders) == 11, \"Should be 11 folders\"\n",
    "\n",
    "# # Get files\n",
    "# for folder in folders:\n",
    "#     print(\"Processing folder: \", folder)\n",
    "#     # Get files\n",
    "#     files = os.listdir(os.path.join(path, folder))\n",
    "#     if os.path.isdir(os.path.join(path, folder, files[0])) and (len(files) == 1):\n",
    "#         files_new = os.listdir(os.path.join(path, folder, files[0]))\n",
    "#         files = [files[0] + \"\\\\\" + file for file in files_new]\n",
    "\n",
    "#     files2concat = []\n",
    "#     for file in files:\n",
    "#         print(\"\\t\\tProcessing file: \", file)\n",
    "#         if file.endswith(\".csv\"):\n",
    "#             # Get data\n",
    "#             try:\n",
    "#                 df_new = pd.read_csv(os.path.join(path, folder, file))\n",
    "#                 # Set experiment name\n",
    "#                 if \"CPPN\" in path:\n",
    "#                     if \"random\" in file:\n",
    "#                         encoding = file.split(\"_random\")[1].split(\"_\")\n",
    "#                     elif \"evo\" in file:\n",
    "#                         encoding = file.split(\"_evo\")[1].split(\"_\")\n",
    "#                     exp_id = (int(encoding[0]) - 1) * 2 + int(encoding[1])\n",
    "#                     df_new[\"experiment_id\"] = exp_id\n",
    "#                 elif \"GRN\" in path:\n",
    "#                     check = file.split(\"_300_\")[1].split(\"_\")\n",
    "#                     if len(check) == 2:\n",
    "#                         encoding = (int(folder) - 1) * 2 + df_new[\"experiment_id\"]\n",
    "#                         df_new[\"experiment_id\"] = encoding\n",
    "#                     else:\n",
    "#                         exp_id = (int(check[0]) - 1) * 2 + int(check[1])\n",
    "#                         df_new[\"experiment_id\"] = exp_id\n",
    "#                 files2concat.append(df_new)\n",
    "#             except Exception as e:\n",
    "#                 pass\n",
    "#     # Add to dataframe\n",
    "#     df = pd.concat(files2concat + [df], ignore_index=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path + \"\\\\Morphology.csv\", \"w\") as f:\n",
    "#     df.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "path_root = \"D:\\\\AI\"\n",
    "paths = {\"GRN\": {\"Random Search\": \"D:\\\\AI\\\\Random\\\\GRN\", \n",
    "                 \"Evolution\": \"C:\\\\Users\\\\niels\\\\Downloads\\\\GRN_runs\"},\n",
    "        \"CPPN\": {\"Random Search\": \"C:\\\\Users\\\\niels\\\\Downloads\\\\CPPN\\\\Random Search\", \n",
    "                \"Evolution\": \"C:\\\\Users\\\\niels\\\\Downloads\\\\CPPN\"},\n",
    "        \"GRN_system\": {\"Random Search\": \"C:\\\\Users\\\\niels\\\\Downloads\\\\GRN_system_runs\\\\Random\",\n",
    "                \"Evolution\": \"C:\\\\Users\\\\niels\\\\Downloads\\\\GRN_system_runs\"},}\n",
    "# Mapping for column names\n",
    "mappings = {'bricks': \"Number of Bricks\", 'hinges': \"Number of Hinges\", 'modules': \"Modules\", \n",
    "            'size': \"Relative Number of Modules\", 'proportion2d': \"Proportion2D\",\n",
    "            \"proportionNiels\": \"Proportion2D_adapted\", 'single_neighbour_brick_ratio': \"Single_Neighbour_Bricks\", \n",
    "            'single_neighbour_ratio': \"Single Neighbours\", 'double_neighbour_brick_and_active_hinge_ratio': \"Double_Neighbours\",\n",
    "            'maxrel_llimbs': 'Attachment Length Max', 'meanrel_llimbs': 'Attachment Length Mean', \n",
    "            'stdrel_llimbs': \"Attachment Length Std\", 'nlimbs': \"Core Attachments\",\n",
    "            'joints': 'Number of Joints', 'joint_brick_ratio': 'Joint-Brick Ratio',\n",
    "            \"surface_area\": \"Surface Area\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "df_exp = pd.DataFrame([])\n",
    "for algorithm, algodata in paths.items():\n",
    "    for mode, path in algodata.items():\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith(\".csv\"):\n",
    "                # Load data\n",
    "                df_new = pd.read_csv(path + \"\\\\\" + file)\n",
    "                df_new[\"Algorithm\"] = algorithm\n",
    "                df_new[\"Mode\"] = mode\n",
    "\n",
    "                # Check and select data\n",
    "                if mode == \"Evolution\":\n",
    "                    # Assert that 600 generations are present\n",
    "                    for exp_id in df_new.loc[:, \"experiment_id\"].unique():\n",
    "                        assert len(df_new.loc[df_new[\"experiment_id\"] == exp_id, \"generation_index\"].unique()) == (1200 + 1)\n",
    "\n",
    "                    # Assert that all even generations have 100 individuals\n",
    "                    assert df_new.loc[df_new[\"generation_index\"] % 2 == 0, :].groupby([\"experiment_id\", \"generation_index\"]).size().unique() == 100\n",
    "                    # Assert that all uneven generations have 50 individuals\n",
    "                    assert df_new.loc[df_new[\"generation_index\"] % 2 != 0, :].groupby([\"experiment_id\", \"generation_index\"]).size().unique() == 50\n",
    "\n",
    "                elif mode == \"Random Search\":\n",
    "                    # Only gen = 0 and offspring\n",
    "                    df_new = df_new.loc[(df_new.loc[:, \"generation_index\"] % 2 != 0) | (df_new.loc[:, \"generation_index\"] == 0), :]\n",
    "                    df_new[\"generation_index\"] = df_new.loc[:, \"generation_index\"].values - (df_new.loc[:, \"generation_index\"].values // 2)\n",
    "                    \n",
    "                    # Assert that all experiments have 51 generations\n",
    "                    for exp_id in df_new.loc[:, \"experiment_id\"].unique():\n",
    "                        assert len(df_new.loc[df_new[\"experiment_id\"] == exp_id, \"generation_index\"].unique()) == 51\n",
    "                    \n",
    "                    \n",
    "                    # Assert that all generations have 50 individuals if not generation 0\n",
    "                    assert df_new.loc[df_new[\"generation_index\"] != 0, :].groupby([\"experiment_id\", \"generation_index\"]).size().unique() == 50\n",
    "                    # Assert that generation 0 has 100 individuals\n",
    "                    assert df_new.loc[df_new[\"generation_index\"] == 0, :].groupby([\"experiment_id\", \"generation_index\"]).size().unique() == 100\n",
    "\n",
    "                # Assert that 20 reps are present\n",
    "                assert len(df_new.loc[:, \"experiment_id\"].unique()) == 20\n",
    "\n",
    "                # Append to existing data\n",
    "                df_exp = pd.concat([df_exp, df_new], ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "df_exp = df_exp.rename(columns=mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Random Data\n",
    "path2random = \"C:\\\\Users\\\\niels\\\\Downloads\\\\Random_runs\"\n",
    "\n",
    "# Get data\n",
    "df_random = pd.DataFrame([])\n",
    "for file in os.listdir(path2random):\n",
    "    if (\"morphological_measures_\" in file) and (file.endswith(\".csv\")):\n",
    "        df_random_new = pd.read_csv(path2random + \"\\\\\" + file)\n",
    "        assert df_random_new[\"count\"].sum() == 60000\n",
    "        df_random = pd.concat([df_random, df_random_new], ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "df_random = df_random.rename(columns=mappings)\n",
    "df_random[\"Algorithm\"] = \"Random\"\n",
    "\n",
    "# Concatenate data\n",
    "df_exp = pd.concat([df_exp, df_random], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maximal symmetry\n",
    "df_exp[\"Symmetry_incl_max\"] = df_exp.loc[:, ['symmetry_incl1', 'symmetry_incl2','symmetry_incl3', 'symmetry_incl4']].max(axis = 1)\n",
    "df_exp[\"Symmetry_excl_max\"] = df_exp.loc[:, ['symmetry_excl1', 'symmetry_excl2','symmetry_excl3', 'symmetry_excl4']].max(axis = 1)\n",
    "# Get median symmetry\n",
    "df_exp[\"Symmetry_incl_median\"] = df_exp.loc[:, ['symmetry_incl1', 'symmetry_incl2','symmetry_incl3', 'symmetry_incl4']].median(axis = 1)\n",
    "df_exp[\"Symmetry_excl_median\"] = df_exp.loc[:, ['symmetry_excl1', 'symmetry_excl2','symmetry_excl3', 'symmetry_excl4']].median(axis = 1)\n",
    "# Get summation symmetry\n",
    "df_exp[\"Symmetry_incl_sum\"] = df_exp.loc[:, ['symmetry_incl1', 'symmetry_incl2','symmetry_incl3', 'symmetry_incl4']].sum(axis = 1) / 4\n",
    "df_exp[\"Symmetry_excl_sum\"] = df_exp.loc[:, ['symmetry_excl1', 'symmetry_excl2','symmetry_excl3', 'symmetry_excl4']].sum(axis = 1) / 4\n",
    "\n",
    "# Get standard deviation symmetry\n",
    "df_exp[\"Symmetry_incl_std\"] = df_exp.loc[:, ['symmetry_incl1', 'symmetry_incl2','symmetry_incl3', 'symmetry_incl4']].std(axis = 1)\n",
    "df_exp[\"Symmetry_excl_std\"] = df_exp.loc[:, ['symmetry_excl1', 'symmetry_excl2','symmetry_excl3', 'symmetry_excl4']].std(axis = 1)\n",
    "\n",
    "# Transform number of limbs\n",
    "df_exp[\"Core Attachments\"] = df_exp[\"Core Attachments\"] / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col1 = \"Number of Hinges\"\n",
    "# col2 = \"Number of Bricks\"\n",
    "\n",
    "# xlwb = df_exp[col1].min()\n",
    "# xupb = df_exp[col1].max()\n",
    "# ylwb = df_exp[col2].min()\n",
    "# yupb = df_exp[col2].max()\n",
    "\n",
    "# plt.subplot(1, 3, 1, aspect='equal')\n",
    "# df2 = df_exp.loc[df_exp[\"Algorithm\"] == \"Random\"].sample(52000, weights = \"count\", replace = True)\n",
    "# df2[col1] = (df2[col1] - xlwb)/(xupb - xlwb)\n",
    "# df2[col2] = (df2[col2] - ylwb)/(yupb - ylwb)\n",
    "# sns.kdeplot(data=df2, x=col1, y=col2, fill=True,)\n",
    "# plt.title(\"Random\")\n",
    "# plt.xlim(0, 1)\n",
    "# plt.ylim(0, 1)\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "\n",
    "# plt.subplot(1, 3, 2, aspect='equal')\n",
    "# df3 = df_exp.loc[df_exp[\"Algorithm\"] == \"CPPN\"]\n",
    "# df3 = df3.loc[df3[\"Mode\"] == \"Random Search\"]\n",
    "# df3[col1] = (df3[col1] - xlwb)/(xupb - xlwb)\n",
    "# df3[col2] = (df3[col2] - ylwb)/(yupb - ylwb)\n",
    "# sns.kdeplot(data=df3, x=col1, y=col2, fill=True, color=\"red\")\n",
    "# plt.title(\"CPPN\")\n",
    "# plt.xlim(0, 1)\n",
    "# plt.ylim(0, 1)\n",
    "# plt.xlabel(\"\")\n",
    "# plt.ylabel(\"\")\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "\n",
    "# plt.subplot(1, 3, 3, aspect='equal')\n",
    "# df4 = df_exp.loc[df_exp[\"Algorithm\"] == \"GRN\"]\n",
    "# df4 = df4.loc[df4[\"Mode\"] == \"Random Search\"]\n",
    "# df4[col1] = (df4[col1] - xlwb)/(xupb - xlwb)\n",
    "# df4[col2] = (df4[col2] - ylwb)/(yupb - ylwb)\n",
    "# sns.kdeplot(data=df4, x=col1, y=col2, fill=True, color=\"orange\")\n",
    "# plt.title(\"GRN\")\n",
    "# plt.xlim(0, 1)\n",
    "# plt.ylim(0, 1)\n",
    "# plt.xlabel(\"\")\n",
    "# plt.ylabel(\"\")\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "\n",
    "\n",
    "# #plt.plot(df2[\"Number of Hinges\"], df2[\"surface_area\"], 'o', markeredgecolor='red', markerfacecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colsn2plot = ['fitness', 'symmetry_incl1', 'symmetry_incl2',\n",
    "#        'symmetry_incl3', 'symmetry_incl4', 'symmetry_excl1', 'symmetry_excl2',\n",
    "#        'symmetry_excl3', 'symmetry_excl4', \"id_string\", \"experiment_id\", \"generation_index\", \"individual_index\", \"Mode\", \"Algorithm\"]\n",
    "# columns2plot = list(df_exp.columns)\n",
    "# for col in colsn2plot:\n",
    "#     columns2plot.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo = \"GRN_system\"\n",
    "# logarithmic = True\n",
    "# unique = False\n",
    "\n",
    "# # for icol, col1 in enumerate(columns2plot):\n",
    "# #     for col2 in columns2plot[icol + 1:]:\n",
    "# for i in range(1):\n",
    "#     for j in range(1):\n",
    "#         col1 = \"Number of Hinges\"\n",
    "#         col2 = \"Number of Bricks\"\n",
    "#         print(col1, col2)\n",
    "#         plt.figure(figsize=(10, 10))\n",
    "#         # ---- Get bounds\n",
    "#         col1lwb = df_exp[col1].min()\n",
    "#         col2lwb = df_exp[col2].min()\n",
    "#         col1upb = df_exp[col1].max()\n",
    "#         col2upb = df_exp[col2].max()\n",
    "\n",
    "#         # ---- Get granularity\n",
    "#         granularities = []\n",
    "#         for col in [col1, col2]:\n",
    "#             if col in [\"Number of Hinges\", \"Number of Bricks\", \"Number of Modules\", \"Number of Limbs\"]:\n",
    "#                 granularities.append(1)\n",
    "#             else:\n",
    "#                 granularities.append(0.01)\n",
    "\n",
    "#         # ---- Get df\n",
    "#         df = df_exp.loc[df_exp[\"Algorithm\"] == algo]\n",
    "#         if algo == \"Random\":\n",
    "#             df = df.sample(30 * 60000, weights = \"count\", replace = True)\n",
    "#         else:\n",
    "#             #df = df.loc[df[\"Mode\"] == \"Random Search\"]\n",
    "#             df = df.loc[df[\"Mode\"] == \"Evolution\"]\n",
    "\n",
    "#         # ---- Get value counts\n",
    "#         if algo == \"Random\":\n",
    "#             if unique:\n",
    "#                 df[\"values\"] = df.groupby([col1, col2]).transform(\"size\") # Unique counts\n",
    "#             else:\n",
    "#                 df[\"values\"] = df.groupby([col1, col2])[\"count\"].transform(\"sum\") # Nonunique counts\n",
    "#         else:\n",
    "#             if unique:\n",
    "#                 df[\"values\"] = df.drop_duplicates([\"id_string\"]).groupby([col1, col2]).transform(\"size\") \n",
    "#             else:\n",
    "#                 df[\"values\"] = df.groupby([col1, col2]).transform(\"size\")\n",
    "\n",
    "#         df = df.drop_duplicates([col1, col2])\n",
    "#         if logarithmic:\n",
    "#             df[\"values\"] = np.log(df[\"values\"] + 1) # Logarithmic scale\n",
    "\n",
    "#         # ---- Get coordinates\n",
    "#         df[\"Row\"] = (df[col1] / granularities[0]).round(2)\n",
    "#         df[\"Column\"] = (df[col2] / granularities[1]).round(2)\n",
    "\n",
    "#         # ---- Add missing values\n",
    "#         rows2append, columns2append = [], []\n",
    "#         for row in range(int(np.round(col1lwb / granularities[0], 2)), int(np.round(col1upb / granularities[0] + 1, 2))):\n",
    "#             for column in range(int(np.round(col2lwb / granularities[1], 2)), int(np.round(col2upb / granularities[1] + 1, 2))):\n",
    "#                 if (row, column) not in zip(df[\"Row\"], df[\"Column\"]):\n",
    "#                     rows2append.append(row)\n",
    "#                     columns2append.append(column)\n",
    "\n",
    "#         # Add to dataframe\n",
    "#         df2append = pd.DataFrame({\"Row\": rows2append, \"Column\": columns2append, \"values\": len(rows2append) * [0]})\n",
    "#         df = pd.concat([df, df2append], ignore_index=True).fillna(0)\n",
    "\n",
    "#         # ---- Scale columns\n",
    "#         df.loc[:, \"Row\"] = (df.loc[:, \"Row\"] * granularities[0] - col1lwb) / (col1upb - col1lwb)\n",
    "#         df.loc[:, \"Column\"] = (df.loc[:, \"Column\"] * granularities[1] - col2lwb) / (col2upb - col2lwb)\n",
    "\n",
    "#         # ---- Pivot table\n",
    "#         df = df.pivot_table(index=\"Row\", columns=\"Column\", values=\"values\", aggfunc=\"sum\", fill_value=0)\n",
    "\n",
    "#         # ---- Get the coordinates and values in the pivot table\n",
    "#         coordinates = []\n",
    "#         for i, index_label in enumerate(df.index):\n",
    "#             for j, column_label in enumerate(df.columns):\n",
    "#                 coordinates.append((index_label, column_label))\n",
    "\n",
    "#         coordinates = np.array(coordinates)\n",
    "#         values = df.values.flatten()\n",
    "\n",
    "#         # ---- Creat a meshgrid\n",
    "#         mins = coordinates.min(axis = 0)\n",
    "#         maxs = coordinates.max(axis = 0)\n",
    "#         grid_x, grid_y = np.mgrid[mins[0]:maxs[0]:1000j, mins[1]:maxs[1]:1000j]\n",
    "\n",
    "#         # ---- Interpolate\n",
    "#         grid_z0 = griddata(coordinates, values, (grid_x, grid_y), method='cubic', fill_value = 0) # nearest, linear, cubic\n",
    "\n",
    "#         # ---- Plot\n",
    "#         plt.imshow(grid_z0.T, extent=(mins[0] - 0.05, maxs[0] + 0.05, mins[1] - 0.05, maxs[1] + 0.05), origin='lower', cmap = \"jet\")\n",
    "\n",
    "#         plt.xlabel(col1, fontsize = 16, fontweight = \"bold\", labelpad = 10)\n",
    "#         plt.ylabel(col2, fontsize = 16, fontweight = \"bold\", labelpad = 10)\n",
    "#         # if logarithmic:\n",
    "#         #     plt.title(\"Logarithmic scale\", fontsize = 16, fontweight = \"bold\")\n",
    "#         # else:\n",
    "#         #     plt.title(\"Non-logarithmic scale\", fontsize = 16, fontweight = \"bold\")\n",
    "#         # Remove ticks\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         # Remove axes\n",
    "#         plt.gca().spines['top'].set_visible(False)\n",
    "#         plt.gca().spines['right'].set_visible(False)\n",
    "#         plt.gca().spines['left'].set_visible(False)\n",
    "#         plt.gca().spines['bottom'].set_visible(False)\n",
    "\n",
    "#         # Remove white padding surrounding the plot\n",
    "#         plt.margins(x = 0, y = 0)\n",
    "\n",
    "#         plt.savefig(f\"D:\\\\AI\\\\Plots\\\\HeatMap\\\\Normal\\\\{algo}\\\\\" + col1 + \"_\" + col2 + \"_\" + algo + \".png\", \n",
    "#                     bbox_inches='tight', dpi = 300, transparent=True)\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.interpolate import griddata\n",
    "\n",
    "# col1 = \"Number of Hinges\"\n",
    "# col2 = \"Number of Bricks\"\n",
    "# logarithmic = True#False#True\n",
    "# unique = False #False\n",
    "\n",
    "# for algo in [\"Random\", \"CPPN\", \"GRN\", \"GRN_system\"]:\n",
    "#     df_transf = (df_exp.loc[:, [col1, col2]] - df_exp.loc[:, [col1, col2]].min(axis = 0)) / (df_exp.loc[:, [col1, col2]].max(axis = 0) - df_exp.loc[:, [col1, col2]].min(axis = 0))\n",
    "\n",
    "#     df = df_exp.loc[df_exp[\"Algorithm\"] == algo]\n",
    "#     if algo == \"Random\":\n",
    "#         df = df.sample(30 * 60000, weights = \"count\", replace = True)\n",
    "#     else:\n",
    "#         df = df.loc[df[\"Mode\"] == \"Random Search\"]#.sample(10000)#, weights = \"count\")\n",
    "\n",
    "#     # Get points\n",
    "#     points = (df.loc[:, [col1, col2]] - df_exp.loc[:, [col1, col2]].min(axis = 0)) / (df_exp.loc[:, [col1, col2]].max(axis = 0) - df_exp.loc[:, [col1, col2]].min(axis = 0))\n",
    "\n",
    "#     if algo == \"Random\":\n",
    "#         if unique:\n",
    "#             points[\"values\"] = df.groupby([col1, col2]).transform(\"size\") # Unique counts\n",
    "#         else:\n",
    "#             points[\"values\"] = df.groupby([col1, col2])[\"count\"].transform(\"sum\") # Nonunique counts\n",
    "#     else:\n",
    "#         if unique:\n",
    "#             points[\"values\"] = df.drop_duplicates([\"id_string\"]).groupby([col1, col2]).transform(\"size\") \n",
    "#         else:\n",
    "#             points[\"values\"] = df.groupby([col1, col2]).transform(\"size\")\n",
    "\n",
    "\n",
    "#     # Drop duplicates\n",
    "#     points = points.drop_duplicates([col1, col2])\n",
    "\n",
    "#     # Add non-existing points\n",
    "#     dict2add = {col1: [], col2: [], \"values\": []}\n",
    "#     added = []\n",
    "#     for key in df_transf.loc[:, [col1, col2]].groupby([col1, col2]).groups.keys():\n",
    "#         list_key = list(key)\n",
    "#         if list_key not in points.loc[:, [col1, col2]].values.tolist():\n",
    "#             if list_key not in added:\n",
    "#                 dict2add[col1].append(list_key[0])\n",
    "#                 dict2add[col2].append(list_key[1])\n",
    "#                 dict2add[\"values\"].append(0)\n",
    "#                 added.append(list_key)\n",
    "\n",
    "#             # dict2add[col1].append(key[0])\n",
    "#             # dict2add[col2].append(key[1])\n",
    "#             # dict2add[\"values\"].append(0)\n",
    "\n",
    "#     # Append to points\n",
    "#     points_new = pd.concat([points, pd.DataFrame(dict2add)], ignore_index=True)\n",
    "        \n",
    "#     # Get values\n",
    "#     values = points_new[\"values\"].values\n",
    "#     if logarithmic:\n",
    "#         values = np.log(values + 1) # Logarithmic scale\n",
    "#     coordinates = points_new.loc[:, [col1, col2]].values\n",
    "\n",
    "#     # Creat a meshgrid\n",
    "#     mins = coordinates.min(axis = 0)\n",
    "#     maxs = coordinates.max(axis = 0)\n",
    "#     grid_x, grid_y = np.mgrid[mins[0]:maxs[0]:1000j, mins[1]:maxs[1]:1000j]\n",
    "\n",
    "#     # Interpolate\n",
    "#     grid_z0 = griddata(coordinates, values, (grid_x, grid_y), method='cubic', fill_value = 0) # nearest, linear, cubic\n",
    "\n",
    "#     # Plot\n",
    "#     plt.imshow(grid_z0.T, extent=(mins[0] - 0.05, maxs[0] + 0.05, mins[1] - 0.05, maxs[1] + 0.05), origin='lower', cmap = \"jet\")\n",
    "#     #plt.scatter(coordinates[:, 0], coordinates[:, 1], c = \"k\")\n",
    "#     plt.xlabel(col1, fontsize = 16, fontweight = \"bold\")\n",
    "#     plt.ylabel(col2, fontsize = 16, fontweight = \"bold\")\n",
    "#     if logarithmic:\n",
    "#         plt.title(\"Logarithmic scale\", fontsize = 16, fontweight = \"bold\")\n",
    "#     else:\n",
    "#         plt.title(\"Non-logarithmic scale\", fontsize = 16, fontweight = \"bold\")\n",
    "\n",
    "#     #plt.plot(points[col1], points[col2], 'o', markeredgecolor='grey', markerfacecolor='none', markersize = 5)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths4plots = [f\"{path_root}\\\\Plots\\\\LinePlots\\\\GRN vs CPPN\\\\Evolution\", f\"{path_root}\\\\Plots\\\\LinePlots\\\\GRN vs CPPN\\\\Random Search\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Random Search\\\\Unique\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Random Search\\\\All\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Evolution\\\\Unique\\\\Offspring\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Evolution\\\\All\\\\Offspring\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Evolution\\\\Unique\\\\Population\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Evolution\\\\All\\\\Population\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Niches\\\\Evolution\", f\"{path_root}\\\\Plots\\\\Niches\\\\Random Search\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Niches\\\\Across_Runs\\\\Evolution\\\\GRN\", f\"{path_root}\\\\Plots\\\\Niches\\\\Across_Runs\\\\Random Search\\\\GRN\",\n",
    "#                f\"{path_root}\\\\Plots\\\\Niches\\\\Across_Runs\\\\Evolution\\\\CPPN\", f\"{path_root}\\\\Plots\\\\Niches\\\\Across_Runs\\\\Random Search\\\\CPPN\",\n",
    "#                f\"{path_root}\\\\Plots\\\\HeatMap\\\\Line\\\\Evolution\\\\CPPN\", f\"{path_root}\\\\Plots\\\\HeatMap\\\\Line\\\\Evolution\\\\GRN\"\n",
    "\n",
    "#                ]\n",
    "# for path in paths4plots:\n",
    "#     if not os.path.exists(path):\n",
    "#         os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set columns to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colsn2plot = ['count', 'symmetry_incl1', 'symmetry_incl2',\n",
    "#        'symmetry_incl3', 'symmetry_incl4', 'symmetry_excl1', 'symmetry_excl2',\n",
    "#        'symmetry_excl3', 'symmetry_excl4', \"id_string\", \"experiment_id\", \"generation_index\", \"individual_index\", \"Mode\", \"Algorithm\"]\n",
    "# columns2plot = list(df_exp.columns)\n",
    "# for col in colsn2plot:\n",
    "#     columns2plot.remove(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Data over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_exp.rename(columns = {\"Single_Neighbours\": \"Single Neighbours\"}, inplace = True)\n",
    "\n",
    "# # ---- Group and apply\n",
    "# for mode in [\"Evolution\"]:\n",
    "#     medians = []\n",
    "#     for algo in [\"CPPN\", \"GRN\", \"GRN_system\"]:\n",
    "#         # Select data of algorithm and mode\n",
    "#         df_exp2 = df_exp.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "#         df_exp2 = df_exp2.loc[df_exp2[\"Mode\"] == mode, :]\n",
    "        \n",
    "#         # Select even generations\n",
    "#         if mode == \"Evolution\":\n",
    "#             df_exp2 = df_exp2.loc[df_exp2[\"generation_index\"] % 2 == 0, :]\n",
    "#             df_exp2.loc[:, \"generation_index\"] = (df_exp2.loc[:, \"generation_index\"] / 2).astype(int)\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "#         # Group and apply\n",
    "#         cols4group = [col for col in df_exp2.columns if col not in colsn2plot or col in [\"generation_index\", \"experiment_id\"]]\t\n",
    "#         median_exp = df_exp2.loc[:, cols4group].groupby([\"generation_index\"]).median()\n",
    "#         std_exp = df_exp2.loc[:, cols4group].groupby([\"generation_index\"]).std()\n",
    "\n",
    "#         # Append\n",
    "#         medians.append((median_exp, std_exp, algo))\n",
    "\n",
    "#     # ---- Plot\n",
    "#     cols2plot = [col for col in columns2plot if col not in [\"id_string\", \"experiment_id\", \"generation_index\", \"individual_index\"]]\n",
    "#     for col in cols2plot:\n",
    "#         lwb = min([(l[0][col] - l[1][col]).min() for l in medians])\n",
    "#         upb = max([(l[0][col] + l[1][col]).max() for l in medians])\n",
    "\n",
    "#         for ivals, vals in enumerate(medians):\n",
    "#             median_exp, std_exp, algo = vals\n",
    "#             color = {\"GRN\": \"brown\", \"GRN_system\": \"grey\", \"CPPN\": \"red\"}[algo]\t\n",
    "#             alpha = {\"GRN\": 0.2, \"GRN_system\": 0.2, \"CPPN\": 0.2}[algo]\n",
    "#             # ---- Mean\n",
    "#             plt.plot(median_exp.index, median_exp.loc[:, col], label = algo, color = color)\n",
    "#             # Std\n",
    "#             plt.fill_between(median_exp.index, median_exp.loc[:, col] - std_exp.loc[:, col], median_exp.loc[:, col] + std_exp.loc[:, col], \n",
    "#                              alpha = alpha, color = color)\n",
    "\n",
    "#             # Set limits\n",
    "#             if mode == \"Evolution\":\n",
    "#                 plt.xlim(0, 601)\n",
    "#             else:\n",
    "#                 plt.xlim(0, 51)\n",
    "#             plt.ylim(lwb - 0.1, upb + 0.1)\n",
    "\n",
    "#             # Set scale\n",
    "#             plt.xscale(\"log\")\n",
    "\n",
    "#             # Set labels\n",
    "#             plt.xlabel(\"Generation\", fontsize = 16, fontweight = \"bold\")\n",
    "#             print(col)\n",
    "#             if col not in [\"Symmetry_incl_sum\", \"Symmetry_incl_std\"]:\n",
    "#                 plt.ylabel(col.title(), fontsize = 16, fontweight = \"bold\")\n",
    "#             elif col == \"Symmetry_incl_sum\":\n",
    "#                 plt.ylabel(\"Symmetry\", fontsize = 16, fontweight = \"bold\")\n",
    "#             elif col == \"Symmetry_incl_std\":\n",
    "#                 plt.ylabel(\"Symmetry Std\", fontsize = 16, fontweight = \"bold\")\n",
    "\n",
    "#             # Set thicker lines\n",
    "#             plt.gca().spines['left'].set_linewidth(2)\n",
    "#             plt.gca().spines['bottom'].set_linewidth(2)\n",
    "\n",
    "#             # Remove axes\n",
    "#             plt.gca().spines['top'].set_visible(False)\n",
    "#             plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "#             # Remove tick markers\n",
    "#             plt.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "#             # Set xtick labels\n",
    "#             plt.xticks([10, 100, 600], [10, 100, 600], fontsize = 10)\n",
    "#             plt.yticks(fontsize = 10)\n",
    "            \n",
    "#             plt.legend()\n",
    "#             plt.grid()\n",
    "        \n",
    "#         if col in [\"Number of Hinges\", \"Number of Bricks\"]:\n",
    "#             plt.ylim(0, 30)\n",
    "#         elif col in [\"Modules\"]:\n",
    "#             plt.ylim(1, 31)\n",
    "#         else:\n",
    "#             plt.ylim(0, 1.1)\n",
    "\n",
    "#         #fig.text(0.5, 0.04, 'Generation', ha='center', va='center')\n",
    "\n",
    "#         # Set common y-axis label\n",
    "#         #fig.text(0.06, 0.5, f'{col.title()}', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "#         # Set common title\n",
    "#         #fig.suptitle(f'{col.title()}', fontsize=16)\n",
    "#         plt.show()\n",
    "#         #plt.savefig(f\"{path_root}\\\\Plots\\\\LinePlots\\\\GRN vs CPPN\\\\{mode}\" + f\"\\\\{col}.png\")\n",
    "#         #plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violin Plots non-evolution Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type_run in [\"All\", \"Unique\"]:\n",
    "#     # Drop evolution data\n",
    "#     df_exp2 = df_exp.loc[df_exp[\"Mode\"] != \"Evolution\", :]\n",
    "\n",
    "#     # ---- Violin plots\n",
    "#     for col in columns2plot:\n",
    "#         # Get data for violin plot\n",
    "#         data4violin = []\n",
    "#         # Select subset of data --> unique bodies or all? + column\n",
    "#         for algo in df_exp2[\"Algorithm\"].unique():\n",
    "#             if algo == \"Random\": continue\n",
    "#             if type_run == \"Unique\":\n",
    "#                 sub_df = df_exp2.loc[df_exp2[\"Algorithm\"] == algo, :].drop_duplicates(subset=['id_string'])\n",
    "#                 sub_df = sub_df.loc[:, [col, \"generation_index\", 'Algorithm', 'Mode']]\n",
    "#             else:\n",
    "#                 sub_df = df_exp2.loc[df_exp2[\"Algorithm\"] == algo, [col, \"generation_index\", 'Algorithm', 'Mode']]\n",
    "\n",
    "#             # Set initialization\n",
    "#             df4init = deepcopy(sub_df.loc[sub_df[\"generation_index\"] == 0, :])\n",
    "#             df4init.loc[:, \"INIT\"] = \"Initialization\"\n",
    "#             sub_df.loc[:, \"INIT\"] = \"Random Search\"\n",
    "#             sub_df = pd.concat([df4init, sub_df], axis=0, ignore_index=True)\n",
    "#             # Append\n",
    "#             data4violin.append(sub_df)\n",
    "        \n",
    "#         # Concat dfs\n",
    "#         data4violin = pd.concat(data4violin, axis=0, ignore_index=True)\n",
    "\n",
    "#         # Group data\n",
    "#         # Plot\n",
    "#         sns.violinplot(data4violin, x = \"Algorithm\", y = col, hue = \"INIT\", split=True, gap=0, inner=\"quart\")\n",
    "#         plt.xlabel(\"Algorithm\", fontsize = 12, fontweight = 'bold')\n",
    "#         plt.ylabel(col.title(), fontsize = 12, fontweight = 'bold')\n",
    "#         plt.title(col.title(), fontsize = 14, fontweight = 'bold')\n",
    "#         # Remove right and top spines\n",
    "#         sns.despine()\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Random Search\" + f\"\\\\{type_run}\\\\{col}.png\")\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_exp[\"Symmetry_incl_sum\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mode = \"Random Search\"\n",
    "# mode = \"Evolution\"\n",
    "# # Initialize\n",
    "# if mode == \"Evolution\":\n",
    "#     fig, ax = plt.subplots(3, 1, figsize=(30, 30))\n",
    "# else:\n",
    "#     fig, ax = plt.subplots(4, 1, figsize=(30, 30))\n",
    "# plt.subplots_adjust(hspace=1)\n",
    "\n",
    "# # for mode in [\"Evolution\", \"Random Search\"]:\n",
    "# # Drop evolution data\n",
    "# df_exp2 = df_exp.loc[df_exp[\"Mode\"] == mode, :]\n",
    "# if mode == \"Evolution\":\n",
    "#     df_exp2 = df_exp2.loc[df_exp2[\"generation_index\"] == 1200, :]\n",
    "\n",
    "# # Append random data n times\n",
    "# rows = []\n",
    "# temporarydf = df_exp2.loc[df_exp2[\"Algorithm\"] == \"Random\", :]\n",
    "# temporarydf = temporarydf.loc[temporarydf[\"count\"] > 1, :]\n",
    "\n",
    "# for irow, row in temporarydf.iterrows():\n",
    "#     if row[\"count\"] != 1:\n",
    "#         rows += [row] * int(row[\"count\"] - 1)\n",
    "        \n",
    "# repeated_df = pd.DataFrame(rows).reset_index(drop=True)\n",
    "# df_exp2 = pd.concat([df_exp2, repeated_df], axis=0, ignore_index=True)\n",
    "\n",
    "# # ---- Violin plots\n",
    "# if mode == \"Evolution\":\n",
    "#     algos = [\"CPPN\", \"GRN\", \"GRN_system\"]\n",
    "# else:\n",
    "#     algos = [\"Random\", \"CPPN\", \"GRN\", \"GRN_system\"]\n",
    "# for ialgo, algo in enumerate(algos):\n",
    "#     # Get data for violin plot\n",
    "#     data4violin = []\n",
    "#     for col in [\"Relative Number of Modules\", \"Joint-Brick Ratio\", \"Number of Limbs\", \"Single_Neighbours\",\n",
    "#                 \"Maximal Length of Limbs\", \"Mean Length of Limbs\", \"Standard Deviation of Limbs\", \"Number of Joints\",\n",
    "#                 \"surface_area\", 'Symmetry_incl_sum', \"Symmetry_incl_std\",\n",
    "#                 ]:\n",
    "\n",
    "#         # Select subset of data --> unique bodies or all? + column\n",
    "#         for type_run in [\"All\", \"Unique\"]:\n",
    "#             if type_run == \"Unique\":\n",
    "#                 sub_df = df_exp2.loc[df_exp2[\"Algorithm\"] == algo, :].drop_duplicates(subset=['id_string'])\n",
    "#                 sub_df = sub_df.loc[:, [col, \"generation_index\"]]\n",
    "#             else:\n",
    "#                 sub_df = df_exp2.loc[df_exp2[\"Algorithm\"] == algo, [col, \"generation_index\"]]\n",
    "\n",
    "#             # Transform\n",
    "#             sub_df[col] = (sub_df[col] - df_exp[col].min()) / (df_exp[col].max() - df_exp[col].min())\n",
    "#             # Append\n",
    "#             sub_df.rename(columns={col: \"Variable\"}, inplace=True)\n",
    "#             sub_df[\"column_label\"] = col\n",
    "#             sub_df[\"Type\"] = type_run\n",
    "#             data4violin.append(sub_df)\n",
    "    \n",
    "#     # Concat dfs\n",
    "#     data4violin = pd.concat(data4violin, axis=0, ignore_index=True)\n",
    "\n",
    "#     # Group data\n",
    "#     # Plot\n",
    "#     sns.violinplot(data4violin, x = \"column_label\", y = \"Variable\", split=True, hue = \"Type\", gap=0, inner=\"quart\",\n",
    "#                    scale = \"width\", ax = ax[ialgo])\n",
    "#     ax[ialgo].set_xlabel(\"\")\n",
    "#     ax[ialgo].set_ylabel(\"\")\n",
    "    \n",
    "#     if ialgo == 0:\n",
    "#         ax[ialgo].set_xticklabels([\"Modules\", \"Joint-Brick Ratio\", \"Core Attachments\", \n",
    "#                     \"Single Neighbours\", \"Number of Joints\", \n",
    "#                     \"Attachment Length Max\", \"Attachment Length Mean\", \"Attachment Length Std\",\n",
    "#                     \"Surface Area\", 'Symmetry', \"Symmetry Std\",\n",
    "#                     ], rotation = 90, fontsize = 20, fontweight = 'bold')\n",
    "#         ax[ialgo].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False, pad = 60,\n",
    "#                               left = False)\n",
    "#     elif (ialgo == 3) or (ialgo == 2 and mode == \"Evolution\"): \n",
    "#         ax[ialgo].set_xticklabels([\"Modules\", \"Joint-Brick Ratio\", \"Core Attachments\", \n",
    "#                     \"Single Neighbours\", \"Number of Joints\", \n",
    "#                     \"Attachment Length Max\", \"Attachment Length Mean\", \"Attachment Length Std\",\n",
    "#                     \"Surface Area\", 'Symmetry', \"Symmetry Std\",\n",
    "#                     ], rotation = 90, fontsize = 20, fontweight = 'bold')\n",
    "#         ax[ialgo].tick_params(pad = 60, left = False)\n",
    "#     else:\n",
    "#         ax[ialgo].set_xticklabels([])\n",
    "#         ax[ialgo].tick_params(pad = 60, left = False)\n",
    "\n",
    "#     ax[ialgo].set_ylim(0, 1)\n",
    "#     ax[ialgo].set_yticklabels([\"\" for tick in ax[ialgo].get_yticks()], fontsize = 20, fontweight = 'bold')\n",
    "#     #ax[ialgo].set_yticklabels([tick.round(2) for tick in ax[ialgo].get_yticks()], fontsize = 20, fontweight = 'bold')\n",
    "#     ax[ialgo].set_title(algo, fontsize = 30, fontweight = 'bold', pad = 20, y= 1.0, loc = \"center\")\n",
    "    \n",
    "#     # Remove right and top spines\n",
    "#     sns.despine(top = True, right = True, left = True)\n",
    "#     ax[ialgo].legend().remove()\n",
    "#     plt.tight_layout()\n",
    "#     #plt.savefig(f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Random Search\" + f\"\\\\{type_run}\\\\{col}.png\")\n",
    "#     #plt.close()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violin Plots over Time (Offspring Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type_run in [\"All\", \"Unique\"]:\n",
    "\n",
    "#     # Drop non-evolution data\n",
    "#     df_exp2 = df_exp.loc[df_exp[\"Mode\"] == \"Evolution\", :]\n",
    "#     # Select only uneven generations\n",
    "#     df_exp2 = df_exp2.loc[df_exp2[\"generation_index\"] % 2 != 0, :]\n",
    "#     df_exp2.loc[:, \"generation_index\"] = df_exp2.loc[:, \"generation_index\"].values - (df_exp2.loc[:, \"generation_index\"].values // 2)\n",
    "#     df_exp3 = deepcopy(df_exp2)\n",
    "#     # ---- Set generation index in steps of 0, 10, 20, 30, 40, 50, 100, 150, 200, 300, 400, 500, 600\n",
    "#     # Where generation index < 10 --> 5\n",
    "#     df_exp3.loc[df_exp2[\"generation_index\"] <= 600, \"generation_index\"] = \"301-600\"\n",
    "#     df_exp3.loc[df_exp2[\"generation_index\"] <= 300, \"generation_index\"] = \"101-300\"\n",
    "#     df_exp3.loc[df_exp2[\"generation_index\"] <= 100, \"generation_index\"] = \"51-100\"\n",
    "#     df_exp3.loc[df_exp2[\"generation_index\"] <= 50, \"generation_index\"] = \"26-50\"\n",
    "#     df_exp3.loc[df_exp2[\"generation_index\"] <= 25, \"generation_index\"] = \"0-25\"\n",
    "\n",
    "#     # ---- Violin plots\n",
    "#     for col in columns2plot:\n",
    "#         # Get data for violin plot\n",
    "#         data4violin = []\n",
    "#         # Select subset of data --> unique bodies or all? + column\n",
    "#         for algo in df_exp3[\"Algorithm\"].unique():\n",
    "#             if type_run == \"Unique\":\n",
    "#                 sub_df = df_exp3.loc[df_exp3[\"Algorithm\"] == algo, :].drop_duplicates(subset=['id_string'])\n",
    "#                 sub_df = sub_df.loc[:, [col, \"generation_index\", 'Algorithm', 'Mode']]\n",
    "#             else:\n",
    "#                 sub_df = df_exp3.loc[df_exp3[\"Algorithm\"] == algo, [col, \"generation_index\", 'Algorithm', 'Mode']]\n",
    "    \n",
    "#             # Append\n",
    "#             data4violin.append(sub_df)\n",
    "        \n",
    "#         # Concat dfs\n",
    "#         data4violin = pd.concat(data4violin, axis=0, ignore_index=True)\n",
    "\n",
    "#         # Group data\n",
    "#         # Plot\n",
    "\n",
    "#         sns.violinplot(data4violin, x = \"generation_index\", y = col, hue = \"Algorithm\", split=True, gap=0, inner=\"quart\",\n",
    "#                        order = [\"0-25\", \"26-50\", \"51-100\", \"101-300\", \"301-600\"])\n",
    "#         plt.xlabel(\"Algorithm\", fontsize = 12, fontweight = 'bold')\n",
    "#         plt.ylabel(col.title(), fontsize = 12, fontweight = 'bold')\n",
    "#         plt.title(col.title(), fontsize = 14, fontweight = 'bold')\n",
    "#         # Remove right and top spines\n",
    "#         sns.despine()\n",
    "#         plt.tight_layout()\n",
    "        \n",
    "#         plt.savefig(f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Evolution\\\\{type_run}\\\\Offspring\" + f\"\\\\{col}.png\")\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://plotly.com/python/v3/density-plots/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Assuming 'measures_heat', 'generation', 'rank', and 'value' are your data and columns\n",
    "# # # Replace these with your actual data and column names\n",
    "# for algo in [\"GRN\", \"CPPN\"]:\n",
    "#     for mode in [\"Evolution\"]:\n",
    "#         # Select data\n",
    "#         df2 = df_exp.loc[df_exp[\"Mode\"] == mode, :]\n",
    "#         df2 = df2.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "\n",
    "#         if mode == \"Evolution\":\n",
    "#             # Select only even generations\n",
    "#             df2 = df2.loc[df2[\"generation_index\"] % 2 == 0, :]\n",
    "#             df2.loc[:, \"generation_index\"] = (df2.loc[:, \"generation_index\"] / 2).astype(int)\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "#         for col in columns2plot:\n",
    "#             # Get a column for each row according to rank within generation based on col\n",
    "#             df2[\"rank\"] = df2.groupby(\"generation_index\")[col].rank(method='first', ascending=True)\n",
    "#             df2pivot = df2.pivot(index = \"rank\", columns = \"generation_index\", values = col)\n",
    "#             # Create the heatmap plot\n",
    "#             heat = sns.heatmap(df2pivot, \n",
    "#                             cmap='inferno', \n",
    "#                             linewidths=0, \n",
    "#                             linecolor='white', vmin = df_exp[col].min(), vmax = df_exp[col].max())\n",
    "            \n",
    "#             # Set the axis labels and title\n",
    "#             heat.set_xlabel('Generations', fontsize=16)\n",
    "#             heat.set_ylabel(\"Robots\", fontsize=16)\n",
    "#             heat.set_title(col.title(), fontsize=16)\n",
    "\n",
    "#             # # Set x-axis ticks\n",
    "#             if mode == \"Evolution\":\n",
    "#                 heat.set_xticks([0, 100, 200, 300, 400, 500, 600])\n",
    "#                 heat.set_xticklabels([0, 100, 200, 300, 400, 500, 600])\n",
    "#             else:\n",
    "#                 heat.set_xticks([0, 10, 20, 30, 40, 50])\n",
    "#                 heat.set_xticklabels([0, 10, 20, 30, 40, 50])\n",
    "\n",
    "#             # Remove y-axis ticks\n",
    "#             heat.set_yticks([])\n",
    "\n",
    "#             # Adjusting the plot layout\n",
    "#             plt.subplots_adjust(top=0.9, right=0.9)\n",
    "\n",
    "#             # Save the plot\n",
    "#             plt.savefig(f\"{path_root}\\\\Plots\\\\HeatMap\\\\Line\\\\{mode}\\\\{algo}\\\\{col}.png\")\n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violin Plots over Time (Population only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type_run in [\"All\", \"Unique\"]:\n",
    "#     # Drop non-evolution data\n",
    "#     df_exp2 = df_exp.loc[df_exp[\"Mode\"] == \"Evolution\", :]\n",
    "#     # Select only even generations\n",
    "#     df_exp2 = df_exp2.loc[df_exp2[\"generation_index\"] % 2 == 0, :]\n",
    "#     df_exp2.loc[:, \"generation_index\"] = (df_exp2.loc[:, \"generation_index\"].values / 2).astype(int)\n",
    "#     df_exp3 = deepcopy(df_exp2)\n",
    "\n",
    "#     # Select where generation_index in  [0, 25, 50, 100, 300, 600]\n",
    "#     df_exp3 = df_exp3.loc[df_exp3[\"generation_index\"].isin([0, 25, 50, 100, 300, 600]), :]\n",
    "\n",
    "#     # ---- Violin plots\n",
    "#     for col in columns2plot:\n",
    "#         # Get data for violin plot\n",
    "#         data4violin = []\n",
    "#         # Select subset of data --> unique bodies or all? + column\n",
    "#         for algo in df_exp3[\"Algorithm\"].unique():\n",
    "#             if type_run == \"Unique\":\n",
    "#                 sub_df = df_exp3.loc[df_exp3[\"Algorithm\"] == algo, :].drop_duplicates(subset=['id_string'])\n",
    "#                 sub_df = sub_df.loc[:, [col, \"generation_index\", 'Algorithm', 'Mode']]\n",
    "#             else:\n",
    "#                 sub_df = df_exp3.loc[df_exp3[\"Algorithm\"] == algo, [col, \"generation_index\", 'Algorithm', 'Mode']]\n",
    "    \n",
    "#             # Append\n",
    "#             data4violin.append(sub_df)\n",
    "        \n",
    "#         # Concat dfs\n",
    "#         data4violin = pd.concat(data4violin, axis=0, ignore_index=True)\n",
    "\n",
    "#         # Group data\n",
    "#         # Plot\n",
    "\n",
    "#         sns.violinplot(data4violin, x = \"generation_index\", y = col, hue = \"Algorithm\", split=True, gap=0, inner=\"quart\",\n",
    "#                        order = [0, 25, 50, 100, 300, 600])\n",
    "#         plt.xlabel(\"Algorithm\", fontsize = 12, fontweight = 'bold')\n",
    "#         plt.ylabel(col.title(), fontsize = 12, fontweight = 'bold')\n",
    "#         plt.title(col.title(), fontsize = 14, fontweight = 'bold')\n",
    "#         # Remove right and top spines\n",
    "#         sns.despine()\n",
    "#         plt.tight_layout()\n",
    "        \n",
    "#         plt.savefig(f\"{path_root}\\\\Plots\\\\Violin\\\\GRN vs CPPN\\\\Evolution\\\\{type_run}\\\\Population\"+ f\"\\\\{col}.png\")\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densities Across Runs (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for algo in df_exp[\"Algorithm\"].unique():\n",
    "#       df2 = df_exp.loc[df_exp[\"Mode\"] == \"Random Search\", :]\n",
    "#       df2 = df2.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "#       for col in columns2plot:\n",
    "#             # Initialize the FacetGrid object\n",
    "#             pal = sns.cubehelix_palette(10, rot=-.25, light=.7)\n",
    "#             g = sns.FacetGrid(df2, row=\"experiment_id\", hue=\"experiment_id\", aspect=15, height=1, palette=pal)\n",
    "\n",
    "\n",
    "#             # Draw the densities in a few steps\n",
    "#             g.map(sns.kdeplot, col,\n",
    "#                   bw_adjust=.5, clip_on=False,\n",
    "#                   fill=True, alpha=1, linewidth=1.5)\n",
    "#             g.map(sns.kdeplot, col, clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "#             # passing color=None to refline() uses the hue mapping\n",
    "#             g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "#             # Define and use a simple function to label the plot in axes coordinates\n",
    "#             def label(x, color, label):\n",
    "#                   ax = plt.gca()\n",
    "#                   ax.text(-0.2, .2, label, fontweight=\"bold\", color=color,\n",
    "#                               ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "#             g.map(label, col)\n",
    "\n",
    "#             # Set the subplots to overlap\n",
    "#             g.figure.subplots_adjust(hspace=0)#-.25)\n",
    "\n",
    "#             # Remove axes details that don't play well with overlap\n",
    "#             g.set_titles(\"\")\n",
    "#             g.set(yticks=[], ylabel=\"\")\n",
    "#             g.despine(bottom=True, left=True)\n",
    "#             plt.savefig(f\"{path_root}\\\\Plots\\\\Niches\\\\Across_Runs\\\\Random Search\\\\{algo}\" + f\"\\\\{col}.png\")\n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niches Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_accumulated_phenotypes(df):\n",
    "#     accumulated = [0]\n",
    "#     database = []\n",
    "#     for gen in df[\"generation_index\"].unique():\n",
    "#         # Get unique phenotypes in generation\n",
    "#         unique_phenotypes = df.loc[df_exp[\"generation_index\"] == gen, \"id_string\"].unique().tolist()\n",
    "#         # Amount not in database\n",
    "#         not_in_db = len(set(unique_phenotypes) - set(database))\n",
    "#         # Add to accumulated\n",
    "#         accumulated.append(accumulated[-1] + not_in_db)\n",
    "#         # Add to database\n",
    "#         database = list(set(database) | set(unique_phenotypes))\n",
    "#     return accumulated\n",
    "\n",
    "\n",
    "# # ---- For all experiments separately: Random Search & Evolution\n",
    "# for mode in [\"Random Search\", \"Evolution\"]:\n",
    "#     for algo in df_exp[\"Algorithm\"].unique():\n",
    "#         accdata = []\n",
    "#         # Get algo and Mode = Random Search\n",
    "#         df_exp2 = df_exp.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "#         df_exp2 = df_exp2.loc[df_exp2[\"Mode\"] == mode, :]\n",
    "\n",
    "#         for exp in df_exp2[\"experiment_id\"].unique():\n",
    "#             accdata.append(get_accumulated_phenotypes(df_exp2.loc[df_exp[\"experiment_id\"] == exp])[1:])\n",
    "\n",
    "#         plt.plot(np.median(accdata, axis = 0), \"-\", label = algo)\n",
    "#         plt.fill_between(range(len(accdata[0])), np.median(accdata, axis = 0) - np.std(accdata, axis = 0), np.median(accdata, axis = 0) + np.std(accdata, axis = 0), alpha = 0.2)\n",
    "#     plt.xlabel(\"Generation\", fontsize = 16, fontweight = 'bold')\n",
    "#     plt.ylabel(\"Unique phenotypes\", fontsize = 16, fontweight = 'bold')\n",
    "#     plt.title(f\"Unique Phenotypes over Time for {mode}\", fontsize = 16, fontweight = 'bold')\n",
    "#     plt.grid()\n",
    "#     plt.tight_layout()\n",
    "#     plt.legend()\n",
    "#     plt.savefig(f\"{path_root}\\\\Plots\\\\Niches\\\\{mode}\" + f\"\\\\accumulated phenotypes median.png\")\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niches Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---- For all experiments together\n",
    "# for mode in [\"Random Search\", \"Evolution\"]:\n",
    "#     for algo in df_exp[\"Algorithm\"].unique():\n",
    "#         accdata = []\n",
    "#         # Get algo and Mode = Random Search\n",
    "#         df_exp2 = df_exp.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "#         df_exp2 = df_exp2.loc[df_exp2[\"Mode\"] == mode, :]\n",
    "#         # Get accumulated phenotypes\n",
    "#         accdata = get_accumulated_phenotypes(df_exp2)[1:]\n",
    "#         # Plot\n",
    "#         plt.plot(accdata, \"-\", label = algo)\n",
    "\n",
    "#     plt.xlabel(\"Generation\", fontsize = 16, fontweight = 'bold')\n",
    "#     plt.ylabel(\"Unique phenotypes\", fontsize = 16, fontweight = 'bold')\n",
    "#     plt.title(f\"Unique Phenotypes over Time for {mode}\", fontsize = 16, fontweight = 'bold')\n",
    "#     plt.grid()\n",
    "#     plt.tight_layout()\n",
    "#     plt.legend()\n",
    "#     plt.savefig(f\"{path_root}\\\\Plots\\\\Niches\\\\{mode}\" + f\"\\\\accumulated phenotypes total.png\")\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niches Sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize\n",
    "# max_x = 0\n",
    "# max_y = 0\n",
    "\n",
    "# for type_scale in [\"log\"]:\n",
    "#     for algo in [\"CPPN\", \"GRN\", \"GRN_system\"]:\n",
    "#         df_exp2 = df_exp.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "#         df_exp2 = df_exp2.loc[df_exp2[\"Mode\"] == \"Random Search\", :]\n",
    "#         # ---- Get plots        \n",
    "#         # Get counts of id_strings, sort by count and plot\n",
    "#         phenotype_counts = df_exp2[\"id_string\"].value_counts()\n",
    "#         phenotype_counts.sort_values(ascending = False, inplace = True)\n",
    "#         # Plot\n",
    "#         if algo == \"CPPN\":\n",
    "#             color = \"k\"\n",
    "#             dash = \"-\"\n",
    "#         elif algo == \"GRN\":\n",
    "#             color = \"grey\"\n",
    "#             dash = \"-\"\n",
    "#         else:\n",
    "#             color = \"k\"\n",
    "#             dash = \"--\"\n",
    "#         plt.plot(phenotype_counts.values, dash, color = color, label = algo)\n",
    "\n",
    "#         # Add arrow\n",
    "#         xloc = (phenotype_counts.values.shape[0] - 1)\n",
    "#         logdistance = (np.log(xloc + 1) - np.log(xloc - 1))\n",
    "#         plt.arrow(xloc, 1, 0, 9,\n",
    "#                    head_width = 0.3 / logdistance, head_length = 3, fc = color, ec = color, linestyle = dash)\n",
    "#         plt.text(xloc, 15, algo, fontsize = 6, color = \"k\", ha = \"center\")\n",
    "\n",
    "#         # ---- Save max values\n",
    "#         if phenotype_counts.values.shape[0] > max_x:\n",
    "#             max_x = phenotype_counts.values.shape[0]\n",
    "#         if max(phenotype_counts.values) > max_y:\n",
    "#             max_y = max(phenotype_counts.values)\n",
    "    \n",
    "#     plt.xlabel(\"IDs\", fontsize = 16, fontweight = 'bold')\n",
    "#     plt.ylabel(\"Frequency\", fontsize = 16, fontweight = 'bold')\n",
    "#     plt.xscale(type_scale)\n",
    "#     plt.yscale(type_scale)\n",
    "#     plt.xlim(0, max_x + 6000)\n",
    "#     plt.ylim(0, max_y)\n",
    "#     #plt.savefig(f\"{path_root}\\\\Plots\\\\Niches\\\\Random Search\" + f\"\\\\phenotype counts_{type_scale}_{algo}.png\")\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.tight_layout()\n",
    "#     # Remove upper and right spines\n",
    "#     plt.gca().spines['right'].set_visible(False)\n",
    "#     plt.gca().spines['top'].set_visible(False)\n",
    "#     # Remove minor ticks\n",
    "#     plt.gca().xaxis.set_minor_locator(plt.NullLocator())\n",
    "#     plt.gca().yaxis.set_minor_locator(plt.NullLocator())\n",
    "#     # Remove ticks but keep labels\n",
    "#     plt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False)\n",
    "\n",
    "#     # Set thicker spines\n",
    "#     ax = plt.gca()\n",
    "#     ax.spines['top'].set_linewidth(2)\n",
    "#     ax.spines['bottom'].set_linewidth(2)\n",
    "#     ax.spines['left'].set_linewidth(2)\n",
    "#     ax.spines['right'].set_linewidth(2)\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bodies to Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from develop_from_string import get_body\n",
    "from itertools import product\n",
    "from revolve2.modular_robot.body.v2 import ActiveHingeV2, BrickV2\n",
    "from revolve2.modular_robot.body.base._core import Core\n",
    "from revolve2.modular_robot.body.v2._attachment_face_core_v2 import AttachmentFaceCoreV2\n",
    "\n",
    "\n",
    "def create_plot(grid, z = 0):\n",
    "    \"\"\"Goal:\n",
    "        Create a plot of the robot.\n",
    "    -------------------------------------------------------\n",
    "    Input:\n",
    "        grid: The grid of the robot\n",
    "    -------------------------------------------------------\n",
    "    Output:\n",
    "        A plot of the robot.\"\"\"\n",
    "    # Create a copy\n",
    "    newgrid = deepcopy(grid)\n",
    "    \n",
    "    # Fill the new grid\n",
    "    for x, y in product(range(grid.shape[0]), range(grid.shape[1])):\n",
    "        if type(grid[x, y, z + 1]) == BrickV2:\n",
    "            newgrid[x, y, z] = 3\n",
    "        elif type(grid[x, y, z + 1]) == ActiveHingeV2:\n",
    "            newgrid[x, y, z] = 2\n",
    "        elif type(grid[x, y, z + 1]) == AttachmentFaceCoreV2:\n",
    "            newgrid[x, y, z] = 1\n",
    "        elif type(grid[x, y, z + 1]) == Core:\n",
    "            newgrid[x, y, z] = 1\n",
    "        else:\n",
    "            newgrid[x, y, z] = 0\n",
    "    \n",
    "    return newgrid[:, :, z].astype(int)\n",
    "\n",
    "def string2grid(string):\n",
    "    # Get max_parts\n",
    "    splitted = string.split(\"|\")\n",
    "    max_parts = int(splitted[0])\n",
    "    # Only core? or should we get the building plan?\n",
    "    if max_parts == 1:\n",
    "        dict_coord = None\n",
    "    elif len(splitted) == 2:\n",
    "        # ---- Get coordinate data\n",
    "        substring = splitted[1]\n",
    "        substring_split = substring.split(\"-\")\n",
    "        # Fill dictionary with building plan\n",
    "        # --> {poslin: [\"B\" or \"H\", {attachment_point: rotation_index}]}\n",
    "        dict_coord = {}\n",
    "        i = 0\n",
    "        while (i != len(substring_split)) and (substring_split[i] != \"\"):\n",
    "            # Linear coordinate\n",
    "            coord = int(substring_split[i])\n",
    "            # Information for that coordinate (type, attachment points and orientations)\n",
    "            info = substring_split[i + 1]\n",
    "            # Set type of module (Brick or Hinge)\n",
    "            dict_coord[coord] = []\n",
    "            dict_coord[coord].append(info[0])\n",
    "            # Set attachment points and orientations\n",
    "            if len(info[1:]) > 1:\n",
    "                dict_coord[coord].append({})\n",
    "                for j in range(int((len(info) - 1) / 2)):\n",
    "                    dict_coord[coord][1][int(info[1 + int(j * 2)])] = int(info[1 + (int(j * 2) + 1)])\n",
    "            else:\n",
    "                dict_coord[coord].append({})\n",
    "            # Increase i\n",
    "            i += 2\n",
    "    \n",
    "    # ---- Develop body\n",
    "    body = get_body(max_parts, dict_coord)\n",
    "\n",
    "    # ---- Get Grid\n",
    "    grid, core_grid_position, id_string = body.to_grid(ActiveHingeV2, BrickV2)\n",
    "    assert string == id_string, \"Error in string to grid conversion\"\n",
    "\n",
    "    # ---- Grid to image\n",
    "    grid = create_plot(grid)\n",
    "            \n",
    "    return grid, core_grid_position\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbodies = 10\n",
    "# nalgos = 4\n",
    "# matrix = np.zeros((nalgos * 61, nbodies * 61)).astype(int) # (29 * 2) + 3 = 61\n",
    "# texts = {}\n",
    "# plt.figure(figsize = (40, 40))\n",
    "\n",
    "# mode = \"Random Search\"\n",
    "\n",
    "# for ialgo, algo in enumerate([\"Random\", \"CPPN\", \"GRN\", \"GRN_system\"]):\n",
    "#     # Get data\n",
    "#     df = df_exp.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "\n",
    "#     # Sort df by count\n",
    "#     if algo == \"Random\":\n",
    "#         df.sort_values(\"count\", ascending = False, ignore_index = True, inplace = True)\n",
    "#     else:\n",
    "#         df = df.loc[df[\"Mode\"] == mode, :]\n",
    "#         if mode == \"Evolution\":\n",
    "#             df = df.loc[df[\"generation_index\"] == 1200, :]\n",
    "#         df.loc[:, \"count\"] = df.groupby(\"id_string\")[\"id_string\"].transform(\"count\").values\n",
    "#         df.drop_duplicates(subset = \"id_string\", inplace = True)\n",
    "#         df.sort_values(\"count\", ascending = False, ignore_index = True, inplace = True)\n",
    "\n",
    "\n",
    "#     for istring, string in enumerate(df[\"id_string\"][0:nbodies]):\n",
    "#         # Get grid\n",
    "#         grid, core_grid_position = string2grid(string)\n",
    "#         # Fill matrix where center is core_grid_position at 16, 16\n",
    "#         rows, cols = grid.shape\n",
    "#         shift1 = 31 - core_grid_position[0]\n",
    "#         shift2 = 31 - core_grid_position[1]\n",
    "\n",
    "#         matrix[ialgo * 61 + shift1:ialgo * 61 + shift1 + rows, \n",
    "#             istring * 61 + shift2:istring * 61 + shift2 + cols] = grid\n",
    "#         # Save text\n",
    "#         texts[(ialgo * 61 + 55, istring * 61 + 30)] = int(df[\"count\"][istring])\n",
    "    \n",
    "\n",
    "# # Create a custom colormap with 4 colors\n",
    "# cmap = plt.cm.colors.ListedColormap(['grey', 'red', 'white', 'blue'])\n",
    "\n",
    "# # Create a normalized color map\n",
    "# norm = plt.cm.colors.Normalize(vmin = 0, vmax = 3)\n",
    "# # Plot the matrix\n",
    "# plt.imshow(matrix, cmap = cmap, norm = norm, interpolation = 'none', aspect = \"equal\", )\n",
    "# # Add text\n",
    "# for key, value in texts.items():\n",
    "#     plt.text(key[1], key[0], str(value), fontsize = 20, color = \"black\", ha = \"center\", va = \"center\")\n",
    "# # Set tick labels\n",
    "# plt.yticks(np.arange(30, 30 + nalgos * 61, 61), [\"Random\", \"CPPN\", \"GRN\", \"GRN_system\"], rotation = 90,\n",
    "#            fontsize = 20, fontweight = 'bold', va = \"center\")\n",
    "# plt.xticks(np.arange(30, 30 + nbodies * 61, 61), \"\",\n",
    "#            fontsize = 20, fontweight = 'bold')\n",
    "# # Remove tick indicators\n",
    "# plt.tick_params(axis='both', which='both', length=0)\n",
    "# # Remove axes\n",
    "# plt.gca().spines['top'].set_visible(False)\n",
    "# plt.gca().spines['right'].set_visible(False)\n",
    "# plt.gca().spines['left'].set_visible(False)\n",
    "# plt.gca().spines['bottom'].set_visible(False)\n",
    "# # Set transparent background\n",
    "# plt.gca().patch.set_alpha(0)\n",
    "# plt.margins(0)\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot4bodies(df, nbodies, path4plots):\n",
    "    \"\"\"Goal:\n",
    "        Code to plot the bodies. By setting df[\"count\"] to \n",
    "        a column we can also get those values as text in \n",
    "        the plot.\n",
    "    -------------------------------------------------------\n",
    "    Input:\n",
    "        df: The dataframe with the bodies\n",
    "        nbodies: The number of bodies to plot in one plot\n",
    "        path4plots: The path to save the plots\"\"\"\n",
    "    # ---- Initialize\n",
    "    assert np.sqrt(nbodies) % 1 == 0, \"Number of bodies should be a square number\"\n",
    "    matrix = np.zeros((int(np.sqrt(nbodies) * 61) + 1, int(np.sqrt(nbodies) * 61) + 1)).astype(int) # (29 * 2) + 3 = 61\n",
    "    texts = {}\n",
    "\n",
    "    # ---- Plot\n",
    "    tot_bodies = 0\n",
    "    while tot_bodies < df.shape[0]:\n",
    "        matrix *= 0\n",
    "        plt.figure(figsize = (100, 100))\n",
    "        for istring, string in enumerate(df[\"id_string\"][tot_bodies:tot_bodies + nbodies]):\n",
    "            row = int(istring // np.sqrt(nbodies))\n",
    "            col = int(istring % np.sqrt(nbodies))\n",
    "            # Get grid\n",
    "            grid, core_grid_position = string2grid(string)\n",
    "            # Fill matrix where center is core_grid_position at 16, 16\n",
    "            rows, cols = grid.shape\n",
    "            shift1 = 31 - core_grid_position[0] # 31 modules --> 0:30\n",
    "            shift2 = 31 - core_grid_position[1]\n",
    "\n",
    "            matrix[row * 61 + shift1:row * 61 + shift1 + rows, \n",
    "                col * 61 + shift2:col * 61 + shift2 + cols] = grid\n",
    "            # Save text\n",
    "            texts[(row * 61 + 55, col * 61 + 30)] = int(df[\"count\"][tot_bodies + istring])\n",
    "            \n",
    "\n",
    "        # Create a custom colormap with 4 colors\n",
    "        cmap = plt.cm.colors.ListedColormap(['grey', 'red', 'white', 'blue'])\n",
    "\n",
    "        # Create a normalized color map\n",
    "        norm = plt.cm.colors.Normalize(vmin = 0, vmax = 3)\n",
    "        # Plot the matrix\n",
    "        plt.imshow(matrix, cmap = cmap, norm = norm, interpolation = 'none', aspect = \"equal\", )\n",
    "        # Add text\n",
    "        for key, value in texts.items():\n",
    "            plt.text(key[1], key[0], str(value), fontsize = 20, color = \"black\", ha = \"center\", va = \"center\")\n",
    "        # Set tick labels\n",
    "        plt.yticks(np.arange(30, 30 + int(np.sqrt(nbodies)) * 61, 61), \n",
    "                [\"1-10\", \"11-20\", \"21-30\", \"31-40\", \"41-50\", \"51-60\", \"61-70\", \"71-80\", \"81-90\", \"91-100\"], \n",
    "                rotation = 90, fontsize = 20, fontweight = 'bold', va = \"center\")\n",
    "\n",
    "        plt.xticks(np.arange(30, 30 + nbodies * 61, 61), \"\",\n",
    "                fontsize = 20, fontweight = 'bold')\n",
    "\n",
    "\n",
    "        # Remove tick indicators\n",
    "        plt.tick_params(axis='both', which='both', length=0)\n",
    "        # Remove axes\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "        plt.gca().spines['left'].set_visible(False)\n",
    "        plt.gca().spines['bottom'].set_visible(False)\n",
    "        # Set transparent background\n",
    "        plt.gca().patch.set_alpha(0)\n",
    "        plt.margins(0)\n",
    "\n",
    "        plt.savefig(path4plots + f\"{tot_bodies}-{tot_bodies + nbodies}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Increase tot_bodies\n",
    "        tot_bodies += nbodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbodies = 100\n",
    "\n",
    "# mode = \"Random Search\"\n",
    "# algo = \"CPPN\"\n",
    "\n",
    "# # Get data\n",
    "# df = df_exp.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "\n",
    "# # Sort df by count\n",
    "# if algo == \"Random\":\n",
    "#     df.sort_values(\"count\", ascending = False, ignore_index = True, inplace = True)\n",
    "# else:\n",
    "#     df = df.loc[df[\"Mode\"] == mode, :]\n",
    "#     # ---- Option 1\n",
    "#     # Per experiment drop duplicates id_string\n",
    "#     #df.drop_duplicates(subset = [\"experiment_id\", \"id_string\"], inplace = True)\n",
    "#     # # Count the number of experiments in which a certain id_string occurs\n",
    "#     # df.loc[:, \"count\"] = df.groupby(\"id_string\")[\"id_string\"].transform(\"count\").values\n",
    "#     # # Only the bodies that occur in more than 5 experiments\n",
    "#     # df.drop_duplicates(subset = \"id_string\", inplace = True)\n",
    "#     # # Keep only if count >= 2\n",
    "#     # df = df.loc[df[\"count\"] >= 2, :]\n",
    "\n",
    "#     # # --- Option 2\n",
    "#     # Count the number of occurences\n",
    "#     df.loc[:, \"count\"] = df.groupby(\"id_string\")[\"id_string\"].transform(\"count\").values\n",
    "#     # Drop duplicates\n",
    "#     df.drop_duplicates(subset = \"id_string\", inplace = True)\n",
    "#     # Only keep if count >= 2\n",
    "#     #df = df.loc[df[\"count\"] >= 2, :]\n",
    "\n",
    "#     # Sort values\n",
    "#     df.sort_values([\"count\", 'Joint-Brick Ratio', \"Number of Joints\", \"Symmetry_excl_sum\"], \n",
    "#                    ascending = False, ignore_index = True, inplace = True)\n",
    "    \n",
    "# plot4bodies(df, nbodies, f\"Images\\\\Random Search\\\\CPPN\\\\{algo}-{mode}-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = deepcopy(df_exp)\n",
    "# Where Algorithm is random search, set mode to a string\n",
    "df.loc[df[\"Algorithm\"] == \"Random\", \"Mode\"] = \"Random Search\"\n",
    "\n",
    "# Only select algos\n",
    "df = df.loc[df[\"Algorithm\"].isin([\"GRN\", \"GRN_system\"]), :]\n",
    "# Only select mode == \"Random Search\"\n",
    "df = df.loc[df[\"Mode\"] == \"Random Search\", :]\n",
    "\n",
    "# Count the number of occurences\n",
    "df[\"count\"] = df.groupby([\"Algorithm\", \"Mode\", \"id_string\"]).transform(\"count\").values\n",
    "df.drop_duplicates(subset = [\"Algorithm\", \"Mode\", \"id_string\"], inplace = True)\n",
    "\n",
    "# Get percentile score for each sample within each algorithm and mode\n",
    "df[\"percentile\"] = df.groupby([\"Algorithm\", \"Mode\"])[\"count\"].rank(pct = True).values\n",
    "\n",
    "# Get values that are all in the 90th percentile\n",
    "def count_above_p(x, p = 0.9):\n",
    "    return (x > p).sum()\n",
    "\n",
    "def single_presence(x):\n",
    "    if x.shape[0] == 1:\n",
    "        return x.iloc[0]\n",
    "    else:\n",
    "        return 0#abs(x.iloc[0] - x.iloc[1])\n",
    "    \n",
    "def rel_difference(x):\n",
    "    if x.shape[0] == 2:\n",
    "        return abs(x.iloc[0] - x.iloc[1]) / min(x.iloc[0], x.iloc[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "scores = df.groupby([\"id_string\"])[\"percentile\"].transform(count_above_p, p = 0.75)\n",
    "#scores = df.groupby([\"id_string\"])[\"count\"].transform(single_presence)\n",
    "#scores = df.groupby([\"id_string\"])[\"count\"].transform(rel_difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Which algorithm to consider\n",
    "# algo2consider = \"GRN_system\"\n",
    "\n",
    "\n",
    "# # # ---- If rel_difference\n",
    "# ## Get scores higher than minimum\n",
    "# strings = df.loc[scores[scores > 1].index, :].reset_index(drop = True)\n",
    "\n",
    "# ## Get samples\n",
    "# # samples = []\n",
    "# # for keystring, string in strings.groupby(\"id_string\"):\n",
    "# #     # Get index of max count\n",
    "# #     idx_max = np.argmax(string[\"count\"])\n",
    "# #     # Get the algorithm with the highest count\n",
    "# #     algo_max = string.iloc[idx_max][\"Algorithm\"]\n",
    "# #     # Get the count of the highest count\n",
    "# #     if algo_max == algo2consider:\n",
    "# #         samples.append(string.iloc[idx_max])\n",
    "\n",
    "# # # Convert to dataframe\n",
    "# # strings = pd.DataFrame(samples)\n",
    "\n",
    "# # ---- Otherwise --> at least 2 samples to prevent to much data\n",
    "# strings = df.loc[scores[scores >= 2].index, :].reset_index(drop = True)\n",
    "\n",
    "# # # Only where algorithm is algo2consider\n",
    "# # strings = strings.loc[strings[\"Algorithm\"] == algo2consider, :].reset_index(drop = True)\n",
    "\n",
    "# # Drop duplicates\n",
    "# strings.drop_duplicates(subset = \"id_string\", inplace = True)\n",
    "\n",
    "# # Sort values\n",
    "# strings.sort_values([\"count\", 'Joint-Brick Ratio', \"Number of Joints\", \"Symmetry_excl_sum\"], inplace = True, ascending = False)\n",
    "\n",
    "# # Reset index\n",
    "# strings.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# # Plot\n",
    "# plot4bodies(strings, 100, f\"Images\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Number of Bricks', 'Number of Hinges', 'Modules',\n",
      "       'Relative Number of Modules', 'Proportion2D', 'Proportion2D_adapted',\n",
      "       'Single_Neighbour_Bricks', 'Single Neighbours', 'Double_Neighbours',\n",
      "       'Attachment Length Max', 'Attachment Length Mean',\n",
      "       'Attachment Length Std', 'Core Attachments', 'Number of Joints',\n",
      "       'Joint-Brick Ratio', 'symmetry_incl1', 'symmetry_incl2',\n",
      "       'symmetry_incl3', 'symmetry_incl4', 'symmetry_excl1', 'symmetry_excl2',\n",
      "       'symmetry_excl3', 'symmetry_excl4', 'coverage', 'branching',\n",
      "       'Surface Area', 'id_string', 'experiment_id', 'generation_index',\n",
      "       'individual_index', 'Algorithm', 'Mode', 'id', 'fitness',\n",
      "       'mapping_seed', 'count', 'Symmetry_incl_max', 'Symmetry_excl_max',\n",
      "       'Symmetry_incl_median', 'Symmetry_excl_median', 'Symmetry_incl_sum',\n",
      "       'Symmetry_excl_sum', 'Symmetry_incl_std', 'Symmetry_excl_std'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = deepcopy(df_exp[0:100])\n",
    "df[\"count\"] = df[\"symmetry_incl1\"] * 100\n",
    "plot4bodies(df, 100, f\"Images\\\\\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = np.zeros((int(2 * 61), int(10 * 61))).astype(int) # (29 * 2) + 3 = 61\n",
    "# texts = {}\n",
    "# plt.figure(figsize = (100, 100))\n",
    "\n",
    "# mode = \"Evolution\"\n",
    "# algo = \"CPPN\"\n",
    "\n",
    "# # Get data\n",
    "# df = df_exp.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "\n",
    "# # Sort df by count\n",
    "# if algo == \"Random\":\n",
    "#     df.sort_values(\"count\", ascending = False, ignore_index = True, inplace = True)\n",
    "# else:\n",
    "#     df = df.loc[df[\"Mode\"] == mode, :]\n",
    "#     if mode == \"Evolution\":\n",
    "#         df = df.loc[df[\"generation_index\"] == 1200, :]\n",
    "\n",
    "#     sandfits = {}\n",
    "#     for exp in df[\"experiment_id\"].unique():\n",
    "#         # Get maximal fitness and accompanying id_string\n",
    "#         maxfit = df.loc[df[\"experiment_id\"] == exp, \"fitness\"].max()\n",
    "#         id_string = df.loc[(df[\"experiment_id\"] == exp) & (df[\"fitness\"] == maxfit), \"id_string\"].values[0]\n",
    "#         # Add to dictionary\n",
    "#         sandfits[id_string] = maxfit\n",
    "    \n",
    "#     # Sort by fitness\n",
    "#     sandfits = {k: v for k, v in sorted(sandfits.items(), key=lambda item: item[1], reverse = True)}\n",
    "\n",
    "# for istring, string in enumerate(list(sandfits.keys())):\n",
    "#     row = int(istring // 10)\n",
    "#     col = int(istring % 10)\n",
    "#     # Get grid\n",
    "#     grid, core_grid_position = string2grid(string)\n",
    "#     # Fill matrix where center is core_grid_position at 16, 16\n",
    "#     rows, cols = grid.shape\n",
    "#     shift1 = 31 - core_grid_position[0]\n",
    "#     shift2 = 31 - core_grid_position[1]\n",
    "\n",
    "#     matrix[row * 61 + shift1:row * 61 + shift1 + rows, \n",
    "#         col * 61 + shift2:col * 61 + shift2 + cols] = grid\n",
    "#     # Save text\n",
    "#     texts[(row * 61 + 55, col * 61 + 30)] = np.round(sandfits[string], 2)\n",
    "    \n",
    "\n",
    "# # Create a custom colormap with 4 colors\n",
    "# cmap = plt.cm.colors.ListedColormap(['grey', 'red', 'white', 'blue'])\n",
    "\n",
    "# # Create a normalized color map\n",
    "# norm = plt.cm.colors.Normalize(vmin = 0, vmax = 3)\n",
    "# # Plot the matrix\n",
    "# plt.imshow(matrix, cmap = cmap, norm = norm, interpolation = 'none', aspect = \"equal\", )\n",
    "# # Add text\n",
    "# for key, value in texts.items():\n",
    "#     plt.text(key[1], key[0], str(value), fontsize = 20, color = \"black\", ha = \"center\", va = \"center\")\n",
    "# # Set tick labels\n",
    "# plt.yticks(np.arange(30, 30 + int(np.sqrt(nbodies)) * 61, 61), \n",
    "#            [\"1-10\", \"11-20\", \"21-30\", \"31-40\", \"41-50\", \"51-60\", \"61-70\", \"71-80\", \"81-90\", \"91-100\"], \n",
    "#            rotation = 90, fontsize = 20, fontweight = 'bold', va = \"center\")\n",
    "# plt.xticks(np.arange(30, 30 + nbodies * 61, 61), \"\",\n",
    "#            fontsize = 20, fontweight = 'bold')\n",
    "\n",
    "\n",
    "# # Remove tick indicators\n",
    "# plt.tick_params(axis='both', which='both', length=0)\n",
    "# # Remove axes\n",
    "# plt.gca().spines['top'].set_visible(False)\n",
    "# plt.gca().spines['right'].set_visible(False)\n",
    "# plt.gca().spines['left'].set_visible(False)\n",
    "# plt.gca().spines['bottom'].set_visible(False)\n",
    "# # Set transparent background\n",
    "# plt.gca().patch.set_alpha(0)\n",
    "# plt.margins(0)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbodies = 20\n",
    "# nalgos = 3\n",
    "# text4behavior = {\"CPPN\": [\"r\", \"r\", \"r\", \"ppu\", \"r\", \"p\", \"r\",\n",
    "#                           \"r\", \"r\", \"r\", \"r\", \"ppu\", \"ppu & r\", \"p\",\n",
    "#                           \"r\", \"ppu & r\", \"r\", \"ppu\", \"r\", \"ppu & r\"],\n",
    "#                 \"GRN\": [\"r\", \"fwst\", \"fwst\", \"r\", \"fwst\", \"rt\", \n",
    "#                         \"ppu\", \"p\", \"p\", \"ppu\", \"ppu\", \"r\", \"ppu\", \"ppu & r\", \"r\",\n",
    "#                         \"p\", \"ppu\", \"ppu\", \"ppu\", \"r\"],\n",
    "#                 \"GRN_system\": [\"fwst\", \"fwst\", \"fwst\", \"fwst\", \"fwst\", \"fwst\",\n",
    "#                                \"p\", \"rt\", \"ppu\", \"wb\", \"rotax\", \"ppu\", \"ppu\", \"p\",\n",
    "#                                \"ppu\", \"p\", \"ppu & r\", \"ppu\", \"ppu\", \"ppu\"]}\n",
    "\n",
    "# # r = roll, ppu = pull and push, p = pull, fwst = forward swing tail, rt = roll with tail,\n",
    "# #\n",
    "# matrix = np.zeros((nalgos * 2 *  (61 + 20), int(nbodies / 2 * 61))).astype(int) # (29 * 2) + 3 = 61\n",
    "# texts = {}\n",
    "# plt.figure(figsize = (40, 40))\n",
    "\n",
    "# for ialgo, algo in enumerate([\"CPPN\", \"GRN\", \"GRN_system\"]):\n",
    "#     # Get data\n",
    "#     df = df_exp.loc[df_exp[\"Algorithm\"] == algo, :]\n",
    "#     df = df.loc[df[\"Mode\"] == \"Evolution\", :]\n",
    "\n",
    "#     # Sort df by fitness\n",
    "#     selected = {}\n",
    "#     for exp in df[\"experiment_id\"].unique():\n",
    "#         # Get maximal fitness and accompanying id_string\n",
    "#         sub_df = df.loc[df[\"experiment_id\"] == exp, :]\n",
    "#         maxfit = sub_df[\"fitness\"].max()\n",
    "#         id_string = sub_df.loc[sub_df[\"fitness\"] == maxfit, \"id_string\"].values[0]\n",
    "#         # Add to dictionary\n",
    "#         selected[exp] = (id_string, maxfit)\n",
    "    \n",
    "#     # Sort by fitness\n",
    "#     selected = dict(sorted(selected.items(), key=lambda item: item[1][1], reverse = True))\n",
    "\n",
    "#     for istring, experiment in enumerate(list(selected.keys())[0:nbodies]):\n",
    "#         # Get string\n",
    "#         string = selected[experiment][0]\n",
    "#         # Get grid\n",
    "#         grid, core_grid_position = string2grid(string)\n",
    "#         # Fill matrix where center is core_grid_position at 16, 16\n",
    "#         rows, cols = grid.shape\n",
    "#         shift1 = 31 - core_grid_position[0]\n",
    "#         shift2 = 31 - core_grid_position[1]\n",
    "\n",
    "#         if istring < 10:\n",
    "#             matrix[ialgo * 2 * (61 + 20) + shift1:ialgo * 2 * (61 + 20) + shift1 + rows, \n",
    "#                 istring * 61 + shift2:istring * 61 + shift2 + cols] = grid\n",
    "#             # Save text\n",
    "#             texts[((ialgo * 2) * (61 + 20) + 55, istring * 61 + 30)] = np.around(selected[experiment][1], 2)\n",
    "#         else:\n",
    "#             matrix[(ialgo * 2 + 1) * (61 + 20) + shift1:(ialgo * 2 + 1) * (61 + 20) + shift1 + rows, \n",
    "#                 (istring - 10) * 61 + shift2:(istring - 10) * 61 + shift2 + cols] = grid\n",
    "#             # Save text\n",
    "#             texts[((ialgo * 2 + 1) * (61 + 20) + 55, (istring - 10) * 61 + 30)] = np.around(selected[experiment][1], 2)\n",
    "\n",
    "# # Create a custom colormap with 4 colors\n",
    "# cmap = plt.cm.colors.ListedColormap(['grey', 'red', 'white', 'blue'])\n",
    "\n",
    "# # Create a normalized color map\n",
    "# norm = plt.cm.colors.Normalize(vmin = 0, vmax = 3)\n",
    "# # Plot the matrix\n",
    "# plt.imshow(matrix, cmap = cmap, norm = norm, interpolation = 'none', aspect = \"equal\", )\n",
    "# # Add text\n",
    "# for itext, key in enumerate(texts):\n",
    "#     value = texts[key]\n",
    "#     plt.text(key[1], key[0], str(value), fontsize = 20, color = \"black\", ha = \"center\", va = \"center\")\n",
    "#     if itext < 20:\n",
    "#         plt.text(key[1], key[0] + 15, text4behavior[\"CPPN\"][itext], fontsize = 20, color = \"black\", ha = \"center\", va = \"center\")\n",
    "#     elif itext < 40:\n",
    "#         plt.text(key[1], key[0] + 15, text4behavior[\"GRN\"][itext - 20], fontsize = 20, color = \"black\", ha = \"center\", va = \"center\")\n",
    "#     elif itext < 60:\n",
    "#         plt.text(key[1], key[0] + 15, text4behavior[\"GRN_system\"][itext - 40], fontsize = 20, color = \"black\", ha = \"center\", va = \"center\")\n",
    "    \n",
    "# # Set tick labels\n",
    "# plt.yticks(np.arange((61 + 20), nalgos * 2 *  (61 + 20), 2 * (61 + 20)), [\"CPPN\", \"GRN\", \"GRN System\"], rotation = 90,\n",
    "#            fontsize = 30, fontweight = 'bold', va = \"center\")\n",
    "# plt.xticks(np.arange(30, 30 + nbodies * (61 + 20), (61 + 20)), \"\",\n",
    "#            fontsize = 20, fontweight = 'bold')\n",
    "# # Horizontal lines\n",
    "# for i in range(0, 2 * nalgos, 2):\n",
    "#     plt.axhline(i * (61 + 20) - 0.5, color = \"black\", linewidth = 2)\n",
    "# # Remove tick indicators\n",
    "# plt.tick_params(axis='both', which='both', length=0)\n",
    "# # Remove axes\n",
    "# plt.gca().spines['top'].set_visible(False)\n",
    "# plt.gca().spines['right'].set_visible(False)\n",
    "# plt.gca().spines['left'].set_visible(False)\n",
    "# plt.gca().spines['bottom'].set_visible(False)\n",
    "# # Set transparent background\n",
    "# plt.gca().patch.set_alpha(0)\n",
    "# plt.margins(0)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x245590a3e80>"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def pad_grid(grid, core_grid_position):\n",
    "#     \"\"\"Goal:\n",
    "#         Pad the grid with empty modules to create a symmetry grid.\n",
    "#     ---------------------------------------------------------------------------\n",
    "#     Input:\n",
    "#         grid: \n",
    "#             The grid of the robot.\n",
    "#     ---------------------------------------------------------------------------\n",
    "#     Output:\n",
    "#         The symmetry grid.\"\"\"\n",
    "#     # Get grid shape\n",
    "#     row, col = grid.shape\n",
    "#     # Position of core\n",
    "#     row_offs, col_offs, _ = core_grid_position\n",
    "#     # Get offsets\n",
    "#     row_off_top = row_offs - 1 # Minus 1 because of 3 x 3 core block\n",
    "#     row_off_bottom = (row - 1) - row_offs - 1 # e.g. 0, 1, 2, 3 --> 4 - 1 - 1 - 1 = 1\n",
    "#     col_off_left = col_offs - 1\n",
    "#     col_off_right = (col - 1) - col_offs - 1\n",
    "\n",
    "#     # Creat empty grid\n",
    "#     diff_off_row = abs(row_off_top - row_off_bottom)\n",
    "#     diff_off_col = abs(col_off_left - col_off_right)\n",
    "#     symmetry_grid = np.empty(shape = (row + diff_off_row, col + diff_off_col), dtype = int)\n",
    "    \n",
    "#     # Fill with None\n",
    "#     symmetry_grid.fill(0)\n",
    "#     # Fill with grid values\n",
    "#     start_row = 0 if row_off_top >= row_off_bottom else diff_off_row\n",
    "#     end_row = row if row_off_top >= row_off_bottom else row + diff_off_row\n",
    "#     start_col = 0 if col_off_left >= col_off_right else diff_off_col\n",
    "#     end_col = col if col_off_left >= col_off_right else col + diff_off_col\n",
    "#     symmetry_grid[start_row:end_row, start_col:end_col] = grid[:, :]\n",
    "\n",
    "#     # Save new core position\n",
    "#     symmetry_core_coordinates = (start_row + row_offs, start_col + col_offs) \n",
    "\n",
    "#     return symmetry_grid, symmetry_core_coordinates\n",
    "\n",
    "\n",
    "string = df.iloc[1][\"id_string\"]\n",
    "grid, core_grid_position = string2grid(string)\n",
    "\n",
    "# Create a custom colormap with 4 colors\n",
    "cmap = plt.cm.colors.ListedColormap(['grey', 'red', 'white', 'blue'])\n",
    "\n",
    "# Create a normalized color map\n",
    "norm = plt.cm.colors.Normalize(vmin = 0, vmax = 3)\n",
    "# Plot the matrix\n",
    "plt.imshow(grid, cmap = cmap, norm = norm, interpolation = 'none', aspect = \"equal\", )\n",
    "\n",
    "# symmetry_grid, symmetry_core_coordinates = pad_grid(grid, core_grid_position)\n",
    "\n",
    "# plt.imshow(symmetry_grid)\n",
    "# plt.grid()\n",
    "\n",
    "# print(sum(sum(symmetry_grid > 0)))\n",
    "\n",
    "\n",
    "# print(symmetry_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1813235"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def calculate_symmetry_diag(symmetry_grid, symmetry_core_coordinates, num_modules):\n",
    "#     \"\"\"Goal:'\n",
    "#         Calculate symmetry along the diagonals.\n",
    "#     ----------------------------------------------------------------------------\n",
    "#     Input:\n",
    "#         symmetry_grid: \n",
    "#             The symmetry grid.\n",
    "#         symmetry_core_coordinates:\n",
    "#             The core coordinates in the symmetry grid.\n",
    "#     ----------------------------------------------------------------------------\n",
    "#     Output:\n",
    "#         * Symmetry along the diagonals including module type\n",
    "#         * Symmetry along the diagonals excluding module type\"\"\"\n",
    "#     # ---- Initialize\n",
    "#     diagsyms = [] # Including module type\n",
    "#     diagsyms_excl = [] # Excluding module type\n",
    "\n",
    "#     # ---- For all diagonals\n",
    "#     for diag in [1, -1]: # 1 is from right to left, -1 is from left to right\n",
    "#         # Initialize\n",
    "#         num_along_plane = 0\n",
    "#         num_symmetrical = 0 # Including module type\n",
    "#         num_symmetrical_excl = 0 # Excluding module type\n",
    "    \n",
    "#         # ---- Find start\n",
    "#         xstart = symmetry_core_coordinates[1]\n",
    "#         ystart = symmetry_core_coordinates[0]\n",
    "#         while True:\n",
    "#             if (((diag == 1) and ((xstart == (symmetry_grid.shape[1] - 1)) or (ystart == 0))) # top right\n",
    "#                 or\n",
    "#                 ((diag == -1) and ((xstart == 0) or (ystart == 0)))): # top left\n",
    "#                 break\n",
    "#             else:\n",
    "#                 xstart += diag * 1 # + if from left to right!\n",
    "#                 ystart -= 1\n",
    "\n",
    "#         # ---- From core towards left top\n",
    "#         ypos = ystart\n",
    "#         xpos = xstart\n",
    "#         while True:\n",
    "#             #print(xpos, ypos)\n",
    "#             if (((diag == 1) and ((xpos < 0) or (ypos > (symmetry_grid.shape[0] - 1)))) # Above left top\n",
    "#                 or\n",
    "#                 ((diag == -1) and ((xpos > (symmetry_grid.shape[1] - 1)) or (ypos > (symmetry_grid.shape[0] - 1))))): # Abpve right top\n",
    "#                 break\n",
    "#             else:\n",
    "#                 # Num along plane\n",
    "#                 if symmetry_grid[ypos, xpos] != 0:\n",
    "#                     num_along_plane += 1\n",
    "#                 # Num symmetrical\n",
    "#                 ypositions = [ypos - (diag * 1), ypos + (diag * 1)] # if from right to left, -1, 1\n",
    "#                 xpositions = [xpos - 1, xpos + 1]\n",
    "#                 while True:\n",
    "#                     if (ypositions[0] < 0) or (ypositions[1] < 0) or (\n",
    "#                         ypositions[0] > (symmetry_grid.shape[0] - 1)) or (\n",
    "#                             ypositions[1] > (symmetry_grid.shape[0] - 1)) or (\n",
    "#                         xpositions[0] < 0) or (xpositions[1] < 0) or (\n",
    "#                         xpositions[0] > (symmetry_grid.shape[1] - 1)) or (\n",
    "#                         xpositions[1] > (symmetry_grid.shape[1] - 1)):\n",
    "#                         break\n",
    "#                     else:\n",
    "#                         # # Within core block?\n",
    "#                         # bool_core = ((xpositions[0] in [symmetry_core_coordinates[1] - 1, symmetry_core_coordinates[1], \n",
    "#                         #         symmetry_core_coordinates[1] + 1])\n",
    "\n",
    "#                         #         and\n",
    "\n",
    "#                         #         (ypositions[0] in [symmetry_core_coordinates[0] - 1, symmetry_core_coordinates[0],\n",
    "#                         #                             symmetry_core_coordinates[0] + 1]))\n",
    "#                         # Check if symmetrical\n",
    "#                         # First\n",
    "#                         if (symmetry_grid[ypositions[0], xpositions[0]] != 0) and (\n",
    "#                             symmetry_grid[ypositions[0], xpositions[0]] ==\n",
    "#                                 symmetry_grid[ypositions[1], xpositions[1]]):\n",
    "#                             # if bool_core:\n",
    "#                             #     pass\n",
    "#                             # else:\n",
    "#                             num_symmetrical += 2\n",
    "#                         # Second (in between)\n",
    "#                         if (ypositions[0] + 1) < symmetry_grid.shape[0]:\n",
    "#                             if (symmetry_grid[ypositions[0] + 1, xpositions[0]] != 0):\n",
    "#                                 print(symmetry_grid[ypositions[0] + 1, xpositions[0]])\n",
    "#                                 print(symmetry_grid[ypositions[1], xpositions[1] - 1])\n",
    "#                                 print('------')\n",
    "#                             if (symmetry_grid[ypositions[0] + 1, xpositions[0]] != 0) and (\n",
    "#                                 symmetry_grid[ypositions[0] + 1, xpositions[0]] ==\n",
    "#                                     symmetry_grid[ypositions[1], xpositions[1] - 1]):\n",
    "#                                 # if bool_core:\n",
    "#                                 #     pass\n",
    "#                                 # else:\n",
    "#                                 print(99999)\n",
    "#                                 num_symmetrical += 2\n",
    "\n",
    "                        \n",
    "#                         if (symmetry_grid[ypositions[0], xpositions[0]] != 0) and (\n",
    "#                             symmetry_grid[ypositions[1], xpositions[1]] != 0):\n",
    "#                             # if bool_core:\n",
    "#                             #     pass\n",
    "#                             # else:\n",
    "#                             num_symmetrical_excl += 2\n",
    "\n",
    "#                         # Adapt positions\n",
    "#                         ypositions[0] -= (diag * 1) # - if from right to left!\n",
    "#                         ypositions[1] += (diag * 1) # + if from right to left!\n",
    "#                         xpositions[0] -= 1\n",
    "#                         xpositions[1] += 1\n",
    "#                 # Adapt positions\n",
    "#                 ypos += 1\n",
    "#                 xpos -= (diag * 1) # - if from right to left!\n",
    "#             #print(num_symmetrical)\n",
    "\n",
    "#         # Calculate difference\n",
    "#         difference = (num_modules + 2) - num_along_plane # + 2 because of 3 x 3 core block\n",
    "\n",
    "#         # Assert\n",
    "#         assert num_symmetrical <= difference\n",
    "#         assert num_symmetrical_excl <= difference\n",
    "#         assert num_symmetrical_excl >= num_symmetrical\n",
    "\n",
    "#         # Calculate the symmetry\n",
    "#         if difference > 0.0:\n",
    "#             diagsyms.append(num_symmetrical / difference)\n",
    "#             diagsyms_excl.append(num_symmetrical_excl / difference)\n",
    "#         else:\n",
    "#             diagsyms.append(difference)\n",
    "#             diagsyms_excl.append(difference)\n",
    "\n",
    "#     return diagsyms, diagsyms_excl\n",
    "\n",
    "# calculate_symmetry_diag(symmetry_grid, symmetry_core_coordinates, df.iloc[11][\"Modules\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2897\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[427], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(istring, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get grid\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m grid, core_grid_position \u001b[38;5;241m=\u001b[39m \u001b[43mstring2grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize\u001b[39;00m\n\u001b[0;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[214], line 69\u001b[0m, in \u001b[0;36mstring2grid\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m     66\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# ---- Develop body\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m body \u001b[38;5;241m=\u001b[39m \u001b[43mget_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_parts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_coord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# ---- Get Grid\u001b[39;00m\n\u001b[0;32m     72\u001b[0m grid, core_grid_position, id_string \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mto_grid(ActiveHingeV2, BrickV2)\n",
      "File \u001b[1;32mc:\\Users\\niels\\OneDrive\\Documenten\\GitHub\\revolve2\\examples\\robot_bodybrain_ea_database\\develop_from_string.py:130\u001b[0m, in \u001b[0;36mget_body\u001b[1;34m(max_parts, dict_coord)\u001b[0m\n\u001b[0;32m    128\u001b[0m rellocslot \u001b[38;5;241m=\u001b[39m (rellocslot_raw \u001b[38;5;241m/\u001b[39m divider) \u001b[38;5;66;03m# to -1, 0, 1\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Add 1 additional for forward position --> 3 x 3 x 3 core instead of 1 x 1 x 1\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m rellocslot \u001b[38;5;241m=\u001b[39m \u001b[43mforward4slot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrellocslot\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# -- Get the linear index of the current position\u001b[39;00m\n\u001b[0;32m    133\u001b[0m poslin_current \u001b[38;5;241m=\u001b[39m pos2lin(position_core \u001b[38;5;241m+\u001b[39m rellocslot, max4grid \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\niels\\OneDrive\\Documenten\\GitHub\\revolve2\\.venv\\lib\\site-packages\\multipledispatch\\dispatcher.py:439\u001b[0m, in \u001b[0;36mMethodDispatcher.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m func:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find signature for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: <\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, str_signature(types))\n\u001b[0;32m    438\u001b[0m     )\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\niels\\OneDrive\\Documenten\\GitHub\\revolve2\\.venv\\lib\\site-packages\\pyrr\\objects\\vector3.py:135\u001b[0m, in \u001b[0;36mVector3.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m((BaseVector3, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m))\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Vector3(\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVector3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__add__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "storage = {}\n",
    "\n",
    "\n",
    "for istring, string in enumerate(df_exp.drop_duplicates(subset = \"id_string\")[\"id_string\"]):\n",
    "    # Print progress\n",
    "    print(istring, end = \"\\r\")\n",
    "\n",
    "    # Get grid\n",
    "    grid, core_grid_position = string2grid(string)\n",
    "\n",
    "    # Initialize\n",
    "    results = []\n",
    "\n",
    "    # How much on each side from center\n",
    "    s1 = (grid.shape[0] - 1) - core_grid_position[0]\n",
    "    s2 = (grid.shape[1] - 1) - core_grid_position[1]\n",
    "    s3 = core_grid_position[0]\n",
    "    s4 = core_grid_position[1]\n",
    "\n",
    "    # Pad new grid with maximum of (s1, s2, s3, s4) at every side\n",
    "    maxside = max(s1, s2, s3, s4)\n",
    "    new_grid = np.zeros((maxside * 2 + 1 , maxside * 2 + 1))\n",
    "\n",
    "    # Place old grid with core at center\n",
    "    assert (new_grid.shape[0] - 1) % 2 == 0, \"New grid should have an odd number of rows\"\n",
    "    middle = int((new_grid.shape[0] - 1) / 2)\n",
    "    new_grid[maxside - s3:maxside - s3 + grid.shape[0], \n",
    "            maxside - s4:maxside - s4 + grid.shape[1]] = grid\n",
    "\n",
    "\n",
    "    for mode in [\"diag1\", \"diag2\", \"horizontal\", \"vertical\"]:\n",
    "        if mode == \"diag1\":\n",
    "            # ---- Left top to right bottom diagonal\n",
    "            # Get lower and upper triangle\n",
    "            lower = np.tril(new_grid, k = -1)\n",
    "            upper = np.triu(new_grid, k = 1)\n",
    "            #upper = np.rot90(np.flipud(upper), 1).astype(int)\n",
    "            upper = np.transpose(upper)\n",
    "\n",
    "        elif mode == \"diag2\":\n",
    "            # ---- Left bottom to right top diagonal\n",
    "            # Get lower and upper triangle\n",
    "            new_grid = np.rot90(new_grid, -1).astype(int)\n",
    "            lower = np.rot90(np.tril(new_grid, k = -1), 1).astype(int)\n",
    "            upper = np.rot90(np.triu(new_grid, k = 1), 1).astype(int)\n",
    "            upper = np.transpose(upper)\n",
    "            upper = np.fliplr(np.flipud(upper))\n",
    "\n",
    "        elif mode == \"vertical\":\n",
    "            # Around vertical axis\n",
    "            upper = new_grid[0:maxside, :]\n",
    "            lower = new_grid[maxside + 1:, :]\n",
    "            upper = np.flipud(upper)\n",
    "        elif mode == \"horizontal\":\n",
    "            # Around horizontal axis\n",
    "            upper = new_grid[:, 0:maxside]\n",
    "            lower = new_grid[:, maxside + 1:]\n",
    "            upper = np.fliplr(upper)\n",
    "            # Create a custom colormap with 4 colors\n",
    "            cmap = plt.cm.colors.ListedColormap(['grey', 'red', 'white', 'blue'])\n",
    "\n",
    "        # ---- Symmetry including type\n",
    "        # Get sum of lower and upper triangle\n",
    "        equality = np.logical_and((upper == lower), (upper != 0))\n",
    "        # Calculate symmetry\n",
    "        counttot = np.sum(upper > 0) + np.sum(lower > 0)\n",
    "        symmetry = np.sum(equality) * 2 / counttot\n",
    "        results.append(symmetry)\n",
    "\n",
    "        # ---- Symmetry excluding type\n",
    "        equality = np.logical_and((upper > 0), (lower > 0))\n",
    "        # Calculate symmetry\n",
    "        symmetry = np.sum(equality) * 2 / counttot\n",
    "        results.append(symmetry)\n",
    "    \n",
    "    # ---- Store values\n",
    "    storage[string] = results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp.drop_duplicates(subset = \"id_string\")[\"id_string\"].to_csv(\"id_strings.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
